[
  {
    "objectID": "rforbeginer.html",
    "href": "rforbeginer.html",
    "title": "Introduction to R",
    "section": "",
    "text": "To install Cran R, you must go to https://cran.r-project.org/, and download the install file for your favorite operating system, click on the .exe, .dmg, .pkg, .deb, respectively for Windows, MacOS and Linux-debian.\nAnd click on follow… until to reach successful installation Then download and install the IDE Rstudio https://www.rstudio.com/products/rstudio/.\nEverything is free to download\n\n\n\nWhere am I?\nTo get the current working directory\n\ngetwd()\n\n[1] \"/Users/marcgarel/OSU/MIO/2023/Projet_2023/Formation_ISBATT/FormationR\"\n\n\nTo change my working directory from the console\n\nsetwd(\"/path/to/my/fancy/project/\")\n\n\n\n\n\n\n\nNote\n\n\n\nIn Rstudio, we can change the working directory by navigating in folder in File panel and clicking on menu More\n\n\nIf you are using a Rproject, you don’t need to change your working directory.\nHow can I find documentation about function?\nThe command help() is the 911\n\n# exemple with function read.table\nhelp(\"read.table\")\n#other exemple of 911\nexample(\"plot\")\n??plot()"
  },
  {
    "objectID": "rforbeginer.html#how-to-install-r",
    "href": "rforbeginer.html#how-to-install-r",
    "title": "Introduction to R",
    "section": "",
    "text": "To install Cran R, you must go to https://cran.r-project.org/, and download the install file for your favorite operating system, click on the .exe, .dmg, .pkg, .deb, respectively for Windows, MacOS and Linux-debian.\nAnd click on follow… until to reach successful installation Then download and install the IDE Rstudio https://www.rstudio.com/products/rstudio/.\nEverything is free to download\n\n\n\nWhere am I?\nTo get the current working directory\n\ngetwd()\n\n[1] \"/Users/marcgarel/OSU/MIO/2023/Projet_2023/Formation_ISBATT/FormationR\"\n\n\nTo change my working directory from the console\n\nsetwd(\"/path/to/my/fancy/project/\")\n\n\n\n\n\n\n\nNote\n\n\n\nIn Rstudio, we can change the working directory by navigating in folder in File panel and clicking on menu More\n\n\nIf you are using a Rproject, you don’t need to change your working directory.\nHow can I find documentation about function?\nThe command help() is the 911\n\n# exemple with function read.table\nhelp(\"read.table\")\n#other exemple of 911\nexample(\"plot\")\n??plot()"
  },
  {
    "objectID": "rforbeginer.html#how-to-use-a-package",
    "href": "rforbeginer.html#how-to-use-a-package",
    "title": "Introduction to R",
    "section": "How to use a package?",
    "text": "How to use a package?\n\nInstallation\nYou can install new packages by clicking directly in Rstudio or by command line (the best way for me)\n\ninstall.packages(\"your_package\") # for packages on CRAN mirror\n\nFor packages from Bioconductor (specifically for bioinformatic):\n\nBiocManager::install(\"your_package\")\n\nor from github (using the package devtools)\n\ndevtools::install_github(\"your_package\")\n\n\n\nUsing functions from a package\nTo use functions from a specific package you can either load the entire package:\n\nlibrary(\"your package1\")\nlibrary(\"your package2\")\nlibrary(\"your package3\")\n\nor call the function this way:\n\nyour_package::yourfunction()\n\nOn your R session using cloud IFB all the necessary packages are installed"
  },
  {
    "objectID": "rforbeginer.html#expression-and-affectation",
    "href": "rforbeginer.html#expression-and-affectation",
    "title": "Introduction to R",
    "section": "Expression and affectation",
    "text": "Expression and affectation\n\nExpression\nAn expression is directly evaluated and the result is displayed on terminal Example :\n\n2 + 3\n\n[1] 5\n\nsqrt(25)\n\n[1] 5\n\n\n\n\nAffectation in an object\nAn assignment is an expression stored in object or variable. In this example expression, constant, array, matrix, data frame, list Example :\n\na=2+3\nb=\"madame\"\n\n\n\n\n\n\n\nWarning\n\n\n\nWhat happens when you execute this cell?\n\n\n\na\n\n[1] 5\n\nb\n\n[1] \"madame\"\n\n\n\na=10\nb=\"5\"\nsomme&lt;-a+b\n\n Why do we have an error ? I need to know the type of the object\n\nstr(a)\nstr(b)\n\n What kind of information do we get?\nWe can also perform mathematical operations on numerical objects.\n\nlog(a) # to obtain the logarithm of a\n\n[1] 1.609438\n\nsqrt(a)# to obtain the square root of a\n\n[1] 2.236068\n\n\n\n# we can compare it\nlog(a)&gt;sqrt(a)\n\n[1] FALSE\n\n\n\n\nType of objects\n\nVectors\nVectors are objects composed by values with the same type or (i.e, numeric, characters…)\n\nV1 &lt;- c(2, 6, 9) # numeric vector\nV2 &lt;- c(\"monday\", \"Tuesday\", \"Wednesday\")# character vector\nV3 &lt;- rep(6, 3) # repetition of the same value\nV4 &lt;- seq(1, 3, 0.1)# sequence of number\nV5 &lt;- 1:100\nV5\n\n  [1]   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n [19]  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n [37]  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n [55]  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n [73]  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n [91]  91  92  93  94  95  96  97  98  99 100\n\n\nTo know the number of value inside a vector\n\nlength(V1)\n\n[1] 3\n\n\nWhat do you think about V4?\nFilter a vector according to criteria\n\n# Example : with list of value (a vector)\n\nx &lt;- c(1, 3, 5, 3, 2, 1, 4, 6, 4, 7, 5, 4, 3)\n\n# get element from 2 to 6\n\nx[2:6]\n\n[1] 3 5 3 2 1\n\n# get elements 3 et 5 from x.\n\nx[c(3, 5)]\n\n[1] 5 2\n\n# get value more than 20.\n\nx[x &gt; 5]\n\n[1] 6 7\n\n# get value of  x where x is equal to 21.\n\nx[x == 5]\n\n[1] 5 5\n\n# return elements form x the the value different from 5\n\nx[x != 5]\n\n [1] 1 3 3 2 1 4 6 4 7 4 3\n\n\nFilter a vector according to several criteria\n\n# 3 lists : ages, sexes et poids\n\nage &lt;- c(20, 30, 40,\n         15, 22, 24,\n         36, 38)\n\nsexe &lt;- c(\"F\", \"M\", \"F\",\n          \"M\", \"F\", \"M\",\n          \"F\", \"M\")\n\npoids &lt;- c(75, 76, 73,\n           72, 64, 76,\n           73, 72)\n\n# get value from age greater than 20 and less than 30.\n\nage[age &gt; 20 & age &lt; 30]\n\n[1] 22 24\n\n# Recovering \"poids\" for those who are older than 25 and female\n\npoids[age &gt; 25 & sexe == \"F\"]\n\n[1] 73 73\n\n#Retrieve age values below 20 or above 30.\n\nage[age &lt; 20 | age &gt; 30]\n\n[1] 40 15 36 38\n\n\nExo1\nConsidering the vector a such as a &lt;- c(\"lannister\", \"targaryen\", \"baratheon\", \"starck\", \"greyjoy\")\n\nWhat is the length of the vector?\nTry doing a[1:3]. What do you get?\nCreate a new vector b containing only lannister and starck.\nTry doing a[-1]. What do you get?\nSort by alphabetical order using sort()\n\nExo2\n\nCreate a vector a containing all integers from 1 to 100.\nAdd the values 200, 201, 202 to the vector a.\nCreate a vector b containing all even integers from 2 to 100 using seq()\n\n\n\nData frames\nData frames are objects composed by vector where the value are of different modes (i.e, numeric, characters…)\n\nData frame examples\nLoad a data frame\n\ndata(iris)\n\nVisualise the data frame in a table\n\nView(iris)\n\nDisplay its internal structure\n\nstr(iris)\n\n'data.frame':   150 obs. of  5 variables:\n $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n $ Species     : Factor w/ 3 levels \"setosa\",\"versicolor\",..: 1 1 1 1 1 1 1 1 1 1 ...\n\n\nWhat can we notice?\n\n\nHow to build your own data frame\n\ndate &lt;- c(\"1_monday\", \"2_Tuesday\", \"3_Wednesday\",\n          \"4_Thursday\", \"5_Friday\", \"6_Sturday\",\n          \"7_Sunday\")\n\nis.character(date)\n\n[1] TRUE\n\n# temperature in deg Celsius\ntemperature &lt;- c(24, 27, 25,\n               22, 30, 21,\n               28)\n\nis.numeric(temperature)\n\n[1] TRUE\n\n# rain in mm\nrain &lt;- c(1, 0, 0,\n          5, 2, 0,\n          0)\n\nis.numeric(rain)\n\n[1] TRUE\n\n# make data.frame\ndf &lt;- data.frame(date, temperature, rain)\nstr(df)\n\n'data.frame':   7 obs. of  3 variables:\n $ date       : chr  \"1_monday\" \"2_Tuesday\" \"3_Wednesday\" \"4_Thursday\" ...\n $ temperature: num  24 27 25 22 30 21 28\n $ rain       : num  1 0 0 5 2 0 0\n\n#To select a column or vector\ndf$temperature\n\n[1] 24 27 25 22 30 21 28\n\ndf[, 2]\n\n[1] 24 27 25 22 30 21 28\n\n# here we use list() instead of c()\n# because there is multiple class in inside row\n\nday &lt;- list(\"8_monday\", 29, 1)\nnew_def &lt;- rbind(df, day)# add row to a data frame\nnew_def\n\n         date temperature rain\n1    1_monday          24    1\n2   2_Tuesday          27    0\n3 3_Wednesday          25    0\n4  4_Thursday          22    5\n5    5_Friday          30    2\n6   6_Sturday          21    0\n7    7_Sunday          28    0\n8    8_monday          29    1"
  },
  {
    "objectID": "rforbeginer.html#functions",
    "href": "rforbeginer.html#functions",
    "title": "Introduction to R",
    "section": "Functions",
    "text": "Functions\n\nDefinition\nFunction are a compilation of command line with different instructions inside one object to simplify code. A function is composed by arguments and options.\nfunction(argument1, argument2, option1, … ,option10)\n\n\nUsual functions for data frame\n\nhead() # to know first line of your data frame\nclass()# return the class of the object. Ex : data.frame, matrix, list ....\nstr()# return the structure of the object. Ex : numeric, factor, character....\nnames()# to get or set the names of an object\nsum() # for addition\nmin() # return the minimum of the vector\nmax() # return the minimum of the vector\nrow.names() # attribute names for lines of the data frame\ncolnames() # attribute names for column of the data frame\napply() # Returns a vector or array or list of values obtained by applying a function to margins of an array or matrix.\n\nExample function row.names, class and str\n\ndf2 &lt;- data.frame(x = c(TRUE, FALSE, NA, NA), y = c(12, 34, 56, 78))\ndf2\n\n      x  y\n1  TRUE 12\n2 FALSE 34\n3    NA 56\n4    NA 78\n\nrow.names(df2) &lt;- paste(\"row\", 1 : 4, sep = \"_\")\ndf2 # what do you see\n\n          x  y\nrow_1  TRUE 12\nrow_2 FALSE 34\nrow_3    NA 56\nrow_4    NA 78\n\nclass(df2)\n\n[1] \"data.frame\"\n\nstr(df2)\n\n'data.frame':   4 obs. of  2 variables:\n $ x: logi  TRUE FALSE NA NA\n $ y: num  12 34 56 78\n\n\nExample function apply\n\nhead(df)\n\n         date temperature rain\n1    1_monday          24    1\n2   2_Tuesday          27    0\n3 3_Wednesday          25    0\n4  4_Thursday          22    5\n5    5_Friday          30    2\n6   6_Sturday          21    0\n\nclass(df)\n\n[1] \"data.frame\"\n\nstr(df)\n\n'data.frame':   7 obs. of  3 variables:\n $ date       : chr  \"1_monday\" \"2_Tuesday\" \"3_Wednesday\" \"4_Thursday\" ...\n $ temperature: num  24 27 25 22 30 21 28\n $ rain       : num  1 0 0 5 2 0 0\n\n# return mean for the numerical column of the data.frame. apply(data,margin,fun). \n# For margin parameter the value 1 return mean for each row, \n# for margin=2 return mean for each selected column.\napply(df[, 2:3], 2, mean)\n\ntemperature        rain \n  25.285714    1.142857 \n\n\nExo 3\nFrom data set iris in package datasets** Load package datasets and load data set iris using data()\n\nGive the class Sepal.Width and Species vectors\nWhat is the minimum / maximum / average sepal length of these irises?\nWhat are the values of the first 10 irises?\nCalculate standard deviation for every numeric vector (function : sd())\nCalculate mean for every numeric vector\nCreate a data frame with mean and sd as line and give a name for each line\nAn error of 0.5cm was made in the measurement of the length of the sepal of the 41st iris: add 0.5cm to this measurement\n\n\n\nUse dplyr to select, filter a data frame\ndplyr is part of the library set named tidyverse (contraction of “tidy” and “universe”, it’s a tidy universe). tidyverse packages are designed to work together and thus follow the same code logic and a common grammar.\nThe pipe, %&gt;%, is one of the useful elements of the tidyverse. It allows to structure sequences of operations by minimizing the creation of intermediate objects and by facilitating the addition of a step anywhere in this sequence. Note that from R 4.1 you can use a new pipe, |&gt; without the need of loading any library.\nThe most commonly used tidyverse packages are loaded in your session:\n\nggplot2\ndplyr\ntidyr\nreadr\ntibble\nstringr\n\n\ntidyverse::tidyverse_packages()\n\n [1] \"broom\"         \"conflicted\"    \"cli\"           \"dbplyr\"       \n [5] \"dplyr\"         \"dtplyr\"        \"forcats\"       \"ggplot2\"      \n [9] \"googledrive\"   \"googlesheets4\" \"haven\"         \"hms\"          \n[13] \"httr\"          \"jsonlite\"      \"lubridate\"     \"magrittr\"     \n[17] \"modelr\"        \"pillar\"        \"purrr\"         \"ragg\"         \n[21] \"readr\"         \"readxl\"        \"reprex\"        \"rlang\"        \n[25] \"rstudioapi\"    \"rvest\"         \"stringr\"       \"tibble\"       \n[29] \"tidyr\"         \"xml2\"          \"tidyverse\"    \n\n\n\nFilter and select variable in data frame\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.3     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.3     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ndata(\"iris\")\n#To select a variable with tidyverse\ndplyr::select(iris, Species)\n\n       Species\n1       setosa\n2       setosa\n3       setosa\n4       setosa\n5       setosa\n6       setosa\n7       setosa\n8       setosa\n9       setosa\n10      setosa\n11      setosa\n12      setosa\n13      setosa\n14      setosa\n15      setosa\n16      setosa\n17      setosa\n18      setosa\n19      setosa\n20      setosa\n21      setosa\n22      setosa\n23      setosa\n24      setosa\n25      setosa\n26      setosa\n27      setosa\n28      setosa\n29      setosa\n30      setosa\n31      setosa\n32      setosa\n33      setosa\n34      setosa\n35      setosa\n36      setosa\n37      setosa\n38      setosa\n39      setosa\n40      setosa\n41      setosa\n42      setosa\n43      setosa\n44      setosa\n45      setosa\n46      setosa\n47      setosa\n48      setosa\n49      setosa\n50      setosa\n51  versicolor\n52  versicolor\n53  versicolor\n54  versicolor\n55  versicolor\n56  versicolor\n57  versicolor\n58  versicolor\n59  versicolor\n60  versicolor\n61  versicolor\n62  versicolor\n63  versicolor\n64  versicolor\n65  versicolor\n66  versicolor\n67  versicolor\n68  versicolor\n69  versicolor\n70  versicolor\n71  versicolor\n72  versicolor\n73  versicolor\n74  versicolor\n75  versicolor\n76  versicolor\n77  versicolor\n78  versicolor\n79  versicolor\n80  versicolor\n81  versicolor\n82  versicolor\n83  versicolor\n84  versicolor\n85  versicolor\n86  versicolor\n87  versicolor\n88  versicolor\n89  versicolor\n90  versicolor\n91  versicolor\n92  versicolor\n93  versicolor\n94  versicolor\n95  versicolor\n96  versicolor\n97  versicolor\n98  versicolor\n99  versicolor\n100 versicolor\n101  virginica\n102  virginica\n103  virginica\n104  virginica\n105  virginica\n106  virginica\n107  virginica\n108  virginica\n109  virginica\n110  virginica\n111  virginica\n112  virginica\n113  virginica\n114  virginica\n115  virginica\n116  virginica\n117  virginica\n118  virginica\n119  virginica\n120  virginica\n121  virginica\n122  virginica\n123  virginica\n124  virginica\n125  virginica\n126  virginica\n127  virginica\n128  virginica\n129  virginica\n130  virginica\n131  virginica\n132  virginica\n133  virginica\n134  virginica\n135  virginica\n136  virginica\n137  virginica\n138  virginica\n139  virginica\n140  virginica\n141  virginica\n142  virginica\n143  virginica\n144  virginica\n145  virginica\n146  virginica\n147  virginica\n148  virginica\n149  virginica\n150  virginica\n\n\n\n#To select several variables with tidyverse\ndplyr::select(iris,Species, Sepal.Length, Sepal.Width)\n\n       Species Sepal.Length Sepal.Width\n1       setosa          5.1         3.5\n2       setosa          4.9         3.0\n3       setosa          4.7         3.2\n4       setosa          4.6         3.1\n5       setosa          5.0         3.6\n6       setosa          5.4         3.9\n7       setosa          4.6         3.4\n8       setosa          5.0         3.4\n9       setosa          4.4         2.9\n10      setosa          4.9         3.1\n11      setosa          5.4         3.7\n12      setosa          4.8         3.4\n13      setosa          4.8         3.0\n14      setosa          4.3         3.0\n15      setosa          5.8         4.0\n16      setosa          5.7         4.4\n17      setosa          5.4         3.9\n18      setosa          5.1         3.5\n19      setosa          5.7         3.8\n20      setosa          5.1         3.8\n21      setosa          5.4         3.4\n22      setosa          5.1         3.7\n23      setosa          4.6         3.6\n24      setosa          5.1         3.3\n25      setosa          4.8         3.4\n26      setosa          5.0         3.0\n27      setosa          5.0         3.4\n28      setosa          5.2         3.5\n29      setosa          5.2         3.4\n30      setosa          4.7         3.2\n31      setosa          4.8         3.1\n32      setosa          5.4         3.4\n33      setosa          5.2         4.1\n34      setosa          5.5         4.2\n35      setosa          4.9         3.1\n36      setosa          5.0         3.2\n37      setosa          5.5         3.5\n38      setosa          4.9         3.6\n39      setosa          4.4         3.0\n40      setosa          5.1         3.4\n41      setosa          5.0         3.5\n42      setosa          4.5         2.3\n43      setosa          4.4         3.2\n44      setosa          5.0         3.5\n45      setosa          5.1         3.8\n46      setosa          4.8         3.0\n47      setosa          5.1         3.8\n48      setosa          4.6         3.2\n49      setosa          5.3         3.7\n50      setosa          5.0         3.3\n51  versicolor          7.0         3.2\n52  versicolor          6.4         3.2\n53  versicolor          6.9         3.1\n54  versicolor          5.5         2.3\n55  versicolor          6.5         2.8\n56  versicolor          5.7         2.8\n57  versicolor          6.3         3.3\n58  versicolor          4.9         2.4\n59  versicolor          6.6         2.9\n60  versicolor          5.2         2.7\n61  versicolor          5.0         2.0\n62  versicolor          5.9         3.0\n63  versicolor          6.0         2.2\n64  versicolor          6.1         2.9\n65  versicolor          5.6         2.9\n66  versicolor          6.7         3.1\n67  versicolor          5.6         3.0\n68  versicolor          5.8         2.7\n69  versicolor          6.2         2.2\n70  versicolor          5.6         2.5\n71  versicolor          5.9         3.2\n72  versicolor          6.1         2.8\n73  versicolor          6.3         2.5\n74  versicolor          6.1         2.8\n75  versicolor          6.4         2.9\n76  versicolor          6.6         3.0\n77  versicolor          6.8         2.8\n78  versicolor          6.7         3.0\n79  versicolor          6.0         2.9\n80  versicolor          5.7         2.6\n81  versicolor          5.5         2.4\n82  versicolor          5.5         2.4\n83  versicolor          5.8         2.7\n84  versicolor          6.0         2.7\n85  versicolor          5.4         3.0\n86  versicolor          6.0         3.4\n87  versicolor          6.7         3.1\n88  versicolor          6.3         2.3\n89  versicolor          5.6         3.0\n90  versicolor          5.5         2.5\n91  versicolor          5.5         2.6\n92  versicolor          6.1         3.0\n93  versicolor          5.8         2.6\n94  versicolor          5.0         2.3\n95  versicolor          5.6         2.7\n96  versicolor          5.7         3.0\n97  versicolor          5.7         2.9\n98  versicolor          6.2         2.9\n99  versicolor          5.1         2.5\n100 versicolor          5.7         2.8\n101  virginica          6.3         3.3\n102  virginica          5.8         2.7\n103  virginica          7.1         3.0\n104  virginica          6.3         2.9\n105  virginica          6.5         3.0\n106  virginica          7.6         3.0\n107  virginica          4.9         2.5\n108  virginica          7.3         2.9\n109  virginica          6.7         2.5\n110  virginica          7.2         3.6\n111  virginica          6.5         3.2\n112  virginica          6.4         2.7\n113  virginica          6.8         3.0\n114  virginica          5.7         2.5\n115  virginica          5.8         2.8\n116  virginica          6.4         3.2\n117  virginica          6.5         3.0\n118  virginica          7.7         3.8\n119  virginica          7.7         2.6\n120  virginica          6.0         2.2\n121  virginica          6.9         3.2\n122  virginica          5.6         2.8\n123  virginica          7.7         2.8\n124  virginica          6.3         2.7\n125  virginica          6.7         3.3\n126  virginica          7.2         3.2\n127  virginica          6.2         2.8\n128  virginica          6.1         3.0\n129  virginica          6.4         2.8\n130  virginica          7.2         3.0\n131  virginica          7.4         2.8\n132  virginica          7.9         3.8\n133  virginica          6.4         2.8\n134  virginica          6.3         2.8\n135  virginica          6.1         2.6\n136  virginica          7.7         3.0\n137  virginica          6.3         3.4\n138  virginica          6.4         3.1\n139  virginica          6.0         3.0\n140  virginica          6.9         3.1\n141  virginica          6.7         3.1\n142  virginica          6.9         3.1\n143  virginica          5.8         2.7\n144  virginica          6.8         3.2\n145  virginica          6.7         3.3\n146  virginica          6.7         3.0\n147  virginica          6.3         2.5\n148  virginica          6.5         3.0\n149  virginica          6.2         3.4\n150  virginica          5.9         3.0\n\n# To select several lines inside data frame \ndplyr::slice(iris,22:30)\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.7          1.5         0.4  setosa\n2          4.6         3.6          1.0         0.2  setosa\n3          5.1         3.3          1.7         0.5  setosa\n4          4.8         3.4          1.9         0.2  setosa\n5          5.0         3.0          1.6         0.2  setosa\n6          5.0         3.4          1.6         0.4  setosa\n7          5.2         3.5          1.5         0.2  setosa\n8          5.2         3.4          1.4         0.2  setosa\n9          4.7         3.2          1.6         0.2  setosa\n\n# I can affect it to an object \n\nsubdata=dplyr::slice(iris,22:30)\n\n#or choosing different lines\nmyline=c(22, 38, 120) # I build a vector containing the line that I want\ndplyr::slice(iris,myline)\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width   Species\n1          5.1         3.7          1.5         0.4    setosa\n2          4.9         3.6          1.4         0.1    setosa\n3          6.0         2.2          5.0         1.5 virginica\n\n\n\n\nBonus : to pipe many function serval function together\n\n\n\n\n\n\nNote\n\n\n\nThe pipe  &gt;| , or %&gt;%, is one of the useful elements of the tidyverse. It allows to structure sequences of operations by minimizing the creation of intermediate objects and by facilitating the addition of a step anywhere in this sequence.\nThe useful command to manage data frame : 1) select() to select vector or variable from a data frame ; 2) filter() is used to subset a data frame, retaining all rows that satisfy your conditions ; mutate() adds new variables and preserves existing ones.\n\n\n\nlibrary(dplyr)\niris %&gt;%\nfilter(Sepal.Length &gt; 6) %&gt;% # filtered using size of Sepal Length\nfilter(Species == \"versicolor\") # and the species \n\n   Sepal.Length Sepal.Width Petal.Length Petal.Width    Species\n1           7.0         3.2          4.7         1.4 versicolor\n2           6.4         3.2          4.5         1.5 versicolor\n3           6.9         3.1          4.9         1.5 versicolor\n4           6.5         2.8          4.6         1.5 versicolor\n5           6.3         3.3          4.7         1.6 versicolor\n6           6.6         2.9          4.6         1.3 versicolor\n7           6.1         2.9          4.7         1.4 versicolor\n8           6.7         3.1          4.4         1.4 versicolor\n9           6.2         2.2          4.5         1.5 versicolor\n10          6.1         2.8          4.0         1.3 versicolor\n11          6.3         2.5          4.9         1.5 versicolor\n12          6.1         2.8          4.7         1.2 versicolor\n13          6.4         2.9          4.3         1.3 versicolor\n14          6.6         3.0          4.4         1.4 versicolor\n15          6.8         2.8          4.8         1.4 versicolor\n16          6.7         3.0          5.0         1.7 versicolor\n17          6.7         3.1          4.7         1.5 versicolor\n18          6.3         2.3          4.4         1.3 versicolor\n19          6.1         3.0          4.6         1.4 versicolor\n20          6.2         2.9          4.3         1.3 versicolor\n\n\n\niris %&gt;%\n select(Sepal.Length, Species) %&gt;%\n mutate(Sepal.Length2 = Sepal.Length * 2)%&gt;%\n mutate(Sepal.Length2_squared = Sepal.Length2 * Sepal.Length2)\n\n    Sepal.Length    Species Sepal.Length2 Sepal.Length2_squared\n1            5.1     setosa          10.2                104.04\n2            4.9     setosa           9.8                 96.04\n3            4.7     setosa           9.4                 88.36\n4            4.6     setosa           9.2                 84.64\n5            5.0     setosa          10.0                100.00\n6            5.4     setosa          10.8                116.64\n7            4.6     setosa           9.2                 84.64\n8            5.0     setosa          10.0                100.00\n9            4.4     setosa           8.8                 77.44\n10           4.9     setosa           9.8                 96.04\n11           5.4     setosa          10.8                116.64\n12           4.8     setosa           9.6                 92.16\n13           4.8     setosa           9.6                 92.16\n14           4.3     setosa           8.6                 73.96\n15           5.8     setosa          11.6                134.56\n16           5.7     setosa          11.4                129.96\n17           5.4     setosa          10.8                116.64\n18           5.1     setosa          10.2                104.04\n19           5.7     setosa          11.4                129.96\n20           5.1     setosa          10.2                104.04\n21           5.4     setosa          10.8                116.64\n22           5.1     setosa          10.2                104.04\n23           4.6     setosa           9.2                 84.64\n24           5.1     setosa          10.2                104.04\n25           4.8     setosa           9.6                 92.16\n26           5.0     setosa          10.0                100.00\n27           5.0     setosa          10.0                100.00\n28           5.2     setosa          10.4                108.16\n29           5.2     setosa          10.4                108.16\n30           4.7     setosa           9.4                 88.36\n31           4.8     setosa           9.6                 92.16\n32           5.4     setosa          10.8                116.64\n33           5.2     setosa          10.4                108.16\n34           5.5     setosa          11.0                121.00\n35           4.9     setosa           9.8                 96.04\n36           5.0     setosa          10.0                100.00\n37           5.5     setosa          11.0                121.00\n38           4.9     setosa           9.8                 96.04\n39           4.4     setosa           8.8                 77.44\n40           5.1     setosa          10.2                104.04\n41           5.0     setosa          10.0                100.00\n42           4.5     setosa           9.0                 81.00\n43           4.4     setosa           8.8                 77.44\n44           5.0     setosa          10.0                100.00\n45           5.1     setosa          10.2                104.04\n46           4.8     setosa           9.6                 92.16\n47           5.1     setosa          10.2                104.04\n48           4.6     setosa           9.2                 84.64\n49           5.3     setosa          10.6                112.36\n50           5.0     setosa          10.0                100.00\n51           7.0 versicolor          14.0                196.00\n52           6.4 versicolor          12.8                163.84\n53           6.9 versicolor          13.8                190.44\n54           5.5 versicolor          11.0                121.00\n55           6.5 versicolor          13.0                169.00\n56           5.7 versicolor          11.4                129.96\n57           6.3 versicolor          12.6                158.76\n58           4.9 versicolor           9.8                 96.04\n59           6.6 versicolor          13.2                174.24\n60           5.2 versicolor          10.4                108.16\n61           5.0 versicolor          10.0                100.00\n62           5.9 versicolor          11.8                139.24\n63           6.0 versicolor          12.0                144.00\n64           6.1 versicolor          12.2                148.84\n65           5.6 versicolor          11.2                125.44\n66           6.7 versicolor          13.4                179.56\n67           5.6 versicolor          11.2                125.44\n68           5.8 versicolor          11.6                134.56\n69           6.2 versicolor          12.4                153.76\n70           5.6 versicolor          11.2                125.44\n71           5.9 versicolor          11.8                139.24\n72           6.1 versicolor          12.2                148.84\n73           6.3 versicolor          12.6                158.76\n74           6.1 versicolor          12.2                148.84\n75           6.4 versicolor          12.8                163.84\n76           6.6 versicolor          13.2                174.24\n77           6.8 versicolor          13.6                184.96\n78           6.7 versicolor          13.4                179.56\n79           6.0 versicolor          12.0                144.00\n80           5.7 versicolor          11.4                129.96\n81           5.5 versicolor          11.0                121.00\n82           5.5 versicolor          11.0                121.00\n83           5.8 versicolor          11.6                134.56\n84           6.0 versicolor          12.0                144.00\n85           5.4 versicolor          10.8                116.64\n86           6.0 versicolor          12.0                144.00\n87           6.7 versicolor          13.4                179.56\n88           6.3 versicolor          12.6                158.76\n89           5.6 versicolor          11.2                125.44\n90           5.5 versicolor          11.0                121.00\n91           5.5 versicolor          11.0                121.00\n92           6.1 versicolor          12.2                148.84\n93           5.8 versicolor          11.6                134.56\n94           5.0 versicolor          10.0                100.00\n95           5.6 versicolor          11.2                125.44\n96           5.7 versicolor          11.4                129.96\n97           5.7 versicolor          11.4                129.96\n98           6.2 versicolor          12.4                153.76\n99           5.1 versicolor          10.2                104.04\n100          5.7 versicolor          11.4                129.96\n101          6.3  virginica          12.6                158.76\n102          5.8  virginica          11.6                134.56\n103          7.1  virginica          14.2                201.64\n104          6.3  virginica          12.6                158.76\n105          6.5  virginica          13.0                169.00\n106          7.6  virginica          15.2                231.04\n107          4.9  virginica           9.8                 96.04\n108          7.3  virginica          14.6                213.16\n109          6.7  virginica          13.4                179.56\n110          7.2  virginica          14.4                207.36\n111          6.5  virginica          13.0                169.00\n112          6.4  virginica          12.8                163.84\n113          6.8  virginica          13.6                184.96\n114          5.7  virginica          11.4                129.96\n115          5.8  virginica          11.6                134.56\n116          6.4  virginica          12.8                163.84\n117          6.5  virginica          13.0                169.00\n118          7.7  virginica          15.4                237.16\n119          7.7  virginica          15.4                237.16\n120          6.0  virginica          12.0                144.00\n121          6.9  virginica          13.8                190.44\n122          5.6  virginica          11.2                125.44\n123          7.7  virginica          15.4                237.16\n124          6.3  virginica          12.6                158.76\n125          6.7  virginica          13.4                179.56\n126          7.2  virginica          14.4                207.36\n127          6.2  virginica          12.4                153.76\n128          6.1  virginica          12.2                148.84\n129          6.4  virginica          12.8                163.84\n130          7.2  virginica          14.4                207.36\n131          7.4  virginica          14.8                219.04\n132          7.9  virginica          15.8                249.64\n133          6.4  virginica          12.8                163.84\n134          6.3  virginica          12.6                158.76\n135          6.1  virginica          12.2                148.84\n136          7.7  virginica          15.4                237.16\n137          6.3  virginica          12.6                158.76\n138          6.4  virginica          12.8                163.84\n139          6.0  virginica          12.0                144.00\n140          6.9  virginica          13.8                190.44\n141          6.7  virginica          13.4                179.56\n142          6.9  virginica          13.8                190.44\n143          5.8  virginica          11.6                134.56\n144          6.8  virginica          13.6                184.96\n145          6.7  virginica          13.4                179.56\n146          6.7  virginica          13.4                179.56\n147          6.3  virginica          12.6                158.76\n148          6.5  virginica          13.0                169.00\n149          6.2  virginica          12.4                153.76\n150          5.9  virginica          11.8                139.24\n\niris %&gt;%\n  select(Sepal.Length, Species) %&gt;%\n  mutate(Sepal.Length = Sepal.Length / mean(Sepal.Length, na.rm = TRUE))\n\n    Sepal.Length    Species\n1      0.8727895     setosa\n2      0.8385625     setosa\n3      0.8043354     setosa\n4      0.7872219     setosa\n5      0.8556760     setosa\n6      0.9241301     setosa\n7      0.7872219     setosa\n8      0.8556760     setosa\n9      0.7529949     setosa\n10     0.8385625     setosa\n11     0.9241301     setosa\n12     0.8214489     setosa\n13     0.8214489     setosa\n14     0.7358813     setosa\n15     0.9925841     setosa\n16     0.9754706     setosa\n17     0.9241301     setosa\n18     0.8727895     setosa\n19     0.9754706     setosa\n20     0.8727895     setosa\n21     0.9241301     setosa\n22     0.8727895     setosa\n23     0.7872219     setosa\n24     0.8727895     setosa\n25     0.8214489     setosa\n26     0.8556760     setosa\n27     0.8556760     setosa\n28     0.8899030     setosa\n29     0.8899030     setosa\n30     0.8043354     setosa\n31     0.8214489     setosa\n32     0.9241301     setosa\n33     0.8899030     setosa\n34     0.9412436     setosa\n35     0.8385625     setosa\n36     0.8556760     setosa\n37     0.9412436     setosa\n38     0.8385625     setosa\n39     0.7529949     setosa\n40     0.8727895     setosa\n41     0.8556760     setosa\n42     0.7701084     setosa\n43     0.7529949     setosa\n44     0.8556760     setosa\n45     0.8727895     setosa\n46     0.8214489     setosa\n47     0.8727895     setosa\n48     0.7872219     setosa\n49     0.9070165     setosa\n50     0.8556760     setosa\n51     1.1979464 versicolor\n52     1.0952653 versicolor\n53     1.1808329 versicolor\n54     0.9412436 versicolor\n55     1.1123788 versicolor\n56     0.9754706 versicolor\n57     1.0781517 versicolor\n58     0.8385625 versicolor\n59     1.1294923 versicolor\n60     0.8899030 versicolor\n61     0.8556760 versicolor\n62     1.0096977 versicolor\n63     1.0268112 versicolor\n64     1.0439247 versicolor\n65     0.9583571 versicolor\n66     1.1466058 versicolor\n67     0.9583571 versicolor\n68     0.9925841 versicolor\n69     1.0610382 versicolor\n70     0.9583571 versicolor\n71     1.0096977 versicolor\n72     1.0439247 versicolor\n73     1.0781517 versicolor\n74     1.0439247 versicolor\n75     1.0952653 versicolor\n76     1.1294923 versicolor\n77     1.1637193 versicolor\n78     1.1466058 versicolor\n79     1.0268112 versicolor\n80     0.9754706 versicolor\n81     0.9412436 versicolor\n82     0.9412436 versicolor\n83     0.9925841 versicolor\n84     1.0268112 versicolor\n85     0.9241301 versicolor\n86     1.0268112 versicolor\n87     1.1466058 versicolor\n88     1.0781517 versicolor\n89     0.9583571 versicolor\n90     0.9412436 versicolor\n91     0.9412436 versicolor\n92     1.0439247 versicolor\n93     0.9925841 versicolor\n94     0.8556760 versicolor\n95     0.9583571 versicolor\n96     0.9754706 versicolor\n97     0.9754706 versicolor\n98     1.0610382 versicolor\n99     0.8727895 versicolor\n100    0.9754706 versicolor\n101    1.0781517  virginica\n102    0.9925841  virginica\n103    1.2150599  virginica\n104    1.0781517  virginica\n105    1.1123788  virginica\n106    1.3006275  virginica\n107    0.8385625  virginica\n108    1.2492869  virginica\n109    1.1466058  virginica\n110    1.2321734  virginica\n111    1.1123788  virginica\n112    1.0952653  virginica\n113    1.1637193  virginica\n114    0.9754706  virginica\n115    0.9925841  virginica\n116    1.0952653  virginica\n117    1.1123788  virginica\n118    1.3177410  virginica\n119    1.3177410  virginica\n120    1.0268112  virginica\n121    1.1808329  virginica\n122    0.9583571  virginica\n123    1.3177410  virginica\n124    1.0781517  virginica\n125    1.1466058  virginica\n126    1.2321734  virginica\n127    1.0610382  virginica\n128    1.0439247  virginica\n129    1.0952653  virginica\n130    1.2321734  virginica\n131    1.2664005  virginica\n132    1.3519681  virginica\n133    1.0952653  virginica\n134    1.0781517  virginica\n135    1.0439247  virginica\n136    1.3177410  virginica\n137    1.0781517  virginica\n138    1.0952653  virginica\n139    1.0268112  virginica\n140    1.1808329  virginica\n141    1.1466058  virginica\n142    1.1808329  virginica\n143    0.9925841  virginica\n144    1.1637193  virginica\n145    1.1466058  virginica\n146    1.1466058  virginica\n147    1.0781517  virginica\n148    1.1123788  virginica\n149    1.0610382  virginica\n150    1.0096977  virginica\n\n#Sepal.Length_norm is calculated using the mean of the Sepal.Length for all data set.\n\niris %&gt;%\n  select(Sepal.Length, Species) %&gt;%\n  group_by(Species) %&gt;%\n  mutate(Sepal.Length_norm = Sepal.Length / mean(Sepal.Length, na.rm = TRUE))\n\n# A tibble: 150 × 3\n# Groups:   Species [3]\n   Sepal.Length Species Sepal.Length_norm\n          &lt;dbl&gt; &lt;fct&gt;               &lt;dbl&gt;\n 1          5.1 setosa              1.02 \n 2          4.9 setosa              0.979\n 3          4.7 setosa              0.939\n 4          4.6 setosa              0.919\n 5          5   setosa              0.999\n 6          5.4 setosa              1.08 \n 7          4.6 setosa              0.919\n 8          5   setosa              0.999\n 9          4.4 setosa              0.879\n10          4.9 setosa              0.979\n# ℹ 140 more rows\n\n# In this last example Sepal.Length_norm is calculated using the mean of the Sepal.Length for each species using group_by()\n\n\n\n\n\n\n\nImportant\n\n\n\nThese commands are non-persistent, no changes are made on the original iris data frame. If you want to store it, you must assign your changes to a object. How do we do ?\n\n\n\niris_modif&lt;-iris %&gt;%\n  select(Sepal.Length, Species) %&gt;%\n  group_by(Species) %&gt;%\n  mutate(Sepal.Length_norm = Sepal.Length / mean(Sepal.Length, na.rm = TRUE))"
  },
  {
    "objectID": "rforbeginer.html#how-to-import-external-data-frame-issue-from-.txt-or-.csv",
    "href": "rforbeginer.html#how-to-import-external-data-frame-issue-from-.txt-or-.csv",
    "title": "Introduction to R",
    "section": "How to import external data frame issue from .txt or .csv",
    "text": "How to import external data frame issue from .txt or .csv\nTo import data set, the function read.table() or read.csv() are commonly used.\nread.table(file, header = FALSE, sep = \"\", dec = \".\", ...)\nThe main parameter are :\n\nfile : add the pathway and the name of the file\nheader : a logical value (TRUE or FALSE)indicating whether the file contains the names of the variables as its first line.\nsep : the field separator character. Values on each line of the file are separated by this character. If sep = “” (the default for read.table) the separator is ‘white space’, that is one or more spaces, tabs, newlines or carriage returns.\ndec : the character used in the file for decimal points.\n\n\nds &lt;- read.table(\"./data/exemple_read.txt\",\n                 header = TRUE,\n                 sep = \";\",\n                 dec = \",\")\nhead(ds)\n\n  Temps Fatigue Traitement\n1     0   7.838          O\n2     0   5.588          O\n3     0   7.838          O\n4     0   1.838          O\n5     0   2.088          O\n6     0   2.088          O\n\n\nWhy I use the parameter header=TRUE ?\n\nTo export data set as .txt to read in excel\nThe function is similar to read.table()\nwrite.table(x, file = \"\", sep = \" \",na = \"NA\", dec = \".\", ... )\n\nx : this is your data.frame\nfile : give a name for your file\nsep : cf read.table\ndec : cf read.table\nna : give a symbole for missing data, by convention is NA\n\n\nwrite.table(ds, \"./data/ds.txt\", sep = \"\\t\", dec = \".\")\n\nTo keep our working directory tidy, we now delete ds.txt\n\nfile.remove(\"ds.txt\")\n\nWarning in file.remove(\"ds.txt\"): cannot remove file 'ds.txt', reason 'No such\nfile or directory'\n\n\n[1] FALSE\n\n\nExo 4\n\nIn the dataset Iris select Sepal Width, Sepal length and Species,to create a new data frame name “subset_iris”\nSave this new data frame as text file"
  },
  {
    "objectID": "Graph.html",
    "href": "Graph.html",
    "title": "Graph",
    "section": "",
    "text": "ggplot2 is a powerfull packages to make a very smart graph “ready to use” for publication. gg means grammar and graph, a concept which describe a graph using grammar. This package belong to tidyverse according to “dplyr”. According to the ggplot2 concept, a graph can be divided into different basic parts:Plot = data + Aesthetics + Geometry\n\ndata : data frame\naesthetics : allows to indicate the x and y variables. It can also be used to control the color, size and shape of the points, etc…\ngeometry : corresponds to the type of graph (histogram, box plot, line plot, …..)\n\n\n\n\n\n\n# if not alraedy done load library ggplot2\nlibrary(ggplot2)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\ndata(iris)\nggplot(data = iris, aes(Sepal.Length, Sepal.Width))+ # scatter plot \n  geom_point()\n\n\n\n\n\n\n\n\nggplot(data = iris, aes(Sepal.Length, Sepal.Width))+ # scatter plot \n  geom_line()\n\n\n\n\n\n\n\n\n\n\n\n# Change size, color and shape in a scatter plot \nggplot(data = iris, aes(Sepal.Length, Sepal.Width))+ # scatter plot \n  geom_point(size=3, color =\"steelblue\", shape=21)  # shape is the same thing wiht classical plot on R\n\n\n\n\n\n\n\n\n\n\n# We can calorize and give a shape by month \nggplot(data = iris, aes(Sepal.Length, Sepal.Width))+ # scatter plot \n  geom_point(aes(color = Species, shape = Species)) # shape is the same thing with classical plot on R\n\n\n\n\n\n\n\nBe carefull alpha option is for transparency and ranged between 0 and 1\n\nggplot(data = iris, aes(Sepal.Width,Sepal.Length))+  \ngeom_point(aes(color = Petal.Width, shape = Species), size = 2,alpha=(0.8))\n\n\n\n\nWhat kind of conclusion we can give me with this kind of graph?\n\n\n\n\n\nggplot(data = iris, aes(Sepal.Width,Sepal.Length))+  \ngeom_point(aes(color = Petal.Width, shape = Species), size = 2,alpha=(0.8))+\nscale_color_gradient(low = \"yellow\", high = \"red\")\n\n\n\n\n\n\n\n# You can change manually color with la fonction scale_color_manual()\nggplot(data = iris, aes(Sepal.Length, Sepal.Width))+ # scatter plot \n geom_point(aes(color = Species, shape = Species))  +\n  scale_color_manual(values = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"))\n\n\n\n#You can store your plot in a variable to print later \np&lt;-ggplot(data = iris, aes(Sepal.Length, Sepal.Width))+ # scatter plot \n geom_point(aes(color = Species, shape = Species))  +\n  scale_color_manual(values = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"))+\n  theme_minimal()\n  \n\nprint(p)\n\n\n\n\nWhat do you see if you play the following command : names(p)?\n\n\n\n\n\n#To arrange the graph we can add some label and change the position of the legend\np + theme(legend.position = \"top\")\n\n\n\np + labs(color = \"Species\", shape= \"Sepcies\",\n  title = \"Sepal Length for each speices\",\n  subtitle = \"is a data frame with 150 cases (rows) and 5 variables\",\n  x = \"Sepal.Length (mm)\", y = \"Sepal.Width (mm)\"\n  )\n\n\n\n\n\n\n\n\np2&lt;-ggplot(data = iris, aes(Sepal.Length,Petal.Length))+ # scatter plot \n  geom_point(size=3, color =\"steelblue\") +\n  stat_smooth(method=lm, se=TRUE, na.rm=TRUE, show.legend = TRUE)\np2 + labs(x = \"Sepal.Length (mm)\", y = \"Pepal.Length (mm)\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nTo get data from the trend\n\nggplot_build(p2)$data[[2]]\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n          x         y      ymin     ymax         se flipped_aes PANEL group\n1  4.300000 0.8898184 0.5928870 1.186750 0.15025965       FALSE     1    -1\n2  4.345570 0.9745065 0.6843700 1.264643 0.14682115       FALSE     1    -1\n3  4.391139 1.0591946 0.7758049 1.342584 0.14340694       FALSE     1    -1\n4  4.436709 1.1438827 0.8671884 1.420577 0.14001881       FALSE     1    -1\n5  4.482278 1.2285708 0.9585165 1.498625 0.13665869       FALSE     1    -1\n6  4.527848 1.3132589 1.0497850 1.576733 0.13332869       FALSE     1    -1\n7  4.573418 1.3979469 1.1409895 1.654904 0.13003114       FALSE     1    -1\n8  4.618987 1.4826350 1.2321248 1.733145 0.12676857       FALSE     1    -1\n9  4.664557 1.5673231 1.3231856 1.811461 0.12354374       FALSE     1    -1\n10 4.710127 1.6520112 1.4141657 1.889857 0.12035969       FALSE     1    -1\n11 4.755696 1.7366993 1.5050587 1.968340 0.11721974       FALSE     1    -1\n12 4.801266 1.8213874 1.5958574 2.046917 0.11412754       FALSE     1    -1\n13 4.846835 1.9060755 1.6865538 2.125597 0.11108706       FALSE     1    -1\n14 4.892405 1.9907635 1.7771394 2.204388 0.10810268       FALSE     1    -1\n15 4.937975 2.0754516 1.8676047 2.283299 0.10517918       FALSE     1    -1\n16 4.983544 2.1601397 1.9579394 2.362340 0.10232176       FALSE     1    -1\n17 5.029114 2.2448278 2.0481322 2.441523 0.09953612       FALSE     1    -1\n18 5.074684 2.3295159 2.1381710 2.520861 0.09682845       FALSE     1    -1\n19 5.120253 2.4142040 2.2280424 2.600366 0.09420548       FALSE     1    -1\n20 5.165823 2.4988921 2.3177320 2.680052 0.09167449       FALSE     1    -1\n21 5.211392 2.5835801 2.4072245 2.759936 0.08924328       FALSE     1    -1\n22 5.256962 2.6682682 2.4965032 2.840033 0.08692025       FALSE     1    -1\n23 5.302532 2.7529563 2.5855505 2.920362 0.08471428       FALSE     1    -1\n24 5.348101 2.8376444 2.6743480 3.000941 0.08263476       FALSE     1    -1\n25 5.393671 2.9223325 2.7628763 3.081789 0.08069145       FALSE     1    -1\n26 5.439241 3.0070206 2.8511155 3.162926 0.07889444       FALSE     1    -1\n27 5.484810 3.0917086 2.9390454 3.244372 0.07725392       FALSE     1    -1\n28 5.530380 3.1763967 3.0266461 3.326147 0.07578006       FALSE     1    -1\n29 5.575949 3.2610848 3.1138978 3.408272 0.07448275       FALSE     1    -1\n30 5.621519 3.3457729 3.2007821 3.490764 0.07337136       FALSE     1    -1\n31 5.667089 3.4304610 3.2872821 3.573640 0.07245446       FALSE     1    -1\n32 5.712658 3.5151491 3.3733831 3.656915 0.07173948       FALSE     1    -1\n33 5.758228 3.5998372 3.4590730 3.740601 0.07123252       FALSE     1    -1\n34 5.803797 3.6845252 3.5443430 3.824707 0.07093803       FALSE     1    -1\n35 5.849367 3.7692133 3.6291879 3.909239 0.07085867       FALSE     1    -1\n36 5.894937 3.8539014 3.7136063 3.994197 0.07099515       FALSE     1    -1\n37 5.940506 3.9385895 3.7976006 4.079578 0.07134624       FALSE     1    -1\n38 5.986076 4.0232776 3.8811770 4.165378 0.07190879       FALSE     1    -1\n39 6.031646 4.1079657 3.9643453 4.251586 0.07267789       FALSE     1    -1\n40 6.077215 4.1926538 4.0471181 4.338189 0.07364708       FALSE     1    -1\n41 6.122785 4.2773418 4.1295109 4.425173 0.07480857       FALSE     1    -1\n42 6.168354 4.3620299 4.2115411 4.512519 0.07615357       FALSE     1    -1\n43 6.213924 4.4467180 4.2932276 4.600208 0.07767254       FALSE     1    -1\n44 6.259494 4.5314061 4.3745899 4.688222 0.07935550       FALSE     1    -1\n45 6.305063 4.6160942 4.4556484 4.776540 0.08119225       FALSE     1    -1\n46 6.350633 4.7007823 4.5364230 4.865141 0.08317259       FALSE     1    -1\n47 6.396203 4.7854704 4.6169337 4.954007 0.08528654       FALSE     1    -1\n48 6.441772 4.8701584 4.6971995 5.043117 0.08752440       FALSE     1    -1\n49 6.487342 4.9548465 4.7772387 5.132454 0.08987692       FALSE     1    -1\n50 6.532911 5.0395346 4.8570686 5.222001 0.09233535       FALSE     1    -1\n51 6.578481 5.1242227 4.9367056 5.311740 0.09489144       FALSE     1    -1\n52 6.624051 5.2089108 5.0161647 5.401657 0.09753752       FALSE     1    -1\n53 6.669620 5.2935989 5.0954600 5.491738 0.10026647       FALSE     1    -1\n54 6.715190 5.3782869 5.1746046 5.581969 0.10307170       FALSE     1    -1\n55 6.760759 5.4629750 5.2536105 5.672340 0.10594715       FALSE     1    -1\n56 6.806329 5.5476631 5.3324885 5.762838 0.10888727       FALSE     1    -1\n57 6.851899 5.6323512 5.4112489 5.853454 0.11188695       FALSE     1    -1\n58 6.897468 5.7170393 5.4899007 5.944178 0.11494153       FALSE     1    -1\n59 6.943038 5.8017274 5.5684525 6.035002 0.11804675       FALSE     1    -1\n60 6.988608 5.8864155 5.6469119 6.125919 0.12119872       FALSE     1    -1\n61 7.034177 5.9711035 5.7252860 6.216921 0.12439388       FALSE     1    -1\n62 7.079747 6.0557916 5.8035811 6.308002 0.12762899       FALSE     1    -1\n63 7.125316 6.1404797 5.8818031 6.399156 0.13090109       FALSE     1    -1\n64 7.170886 6.2251678 5.9599574 6.490378 0.13420747       FALSE     1    -1\n65 7.216456 6.3098559 6.0380488 6.581663 0.13754566       FALSE     1    -1\n66 7.262025 6.3945440 6.1160818 6.673006 0.14091339       FALSE     1    -1\n67 7.307595 6.4792321 6.1940606 6.764404 0.14430861       FALSE     1    -1\n68 7.353165 6.5639201 6.2719887 6.855852 0.14772942       FALSE     1    -1\n69 7.398734 6.6486082 6.3498697 6.947347 0.15117407       FALSE     1    -1\n70 7.444304 6.7332963 6.4277068 7.038886 0.15464098       FALSE     1    -1\n71 7.489873 6.8179844 6.5055028 7.130466 0.15812868       FALSE     1    -1\n72 7.535443 6.9026725 6.5832603 7.222085 0.16163582       FALSE     1    -1\n73 7.581013 6.9873606 6.6609818 7.313739 0.16516118       FALSE     1    -1\n74 7.626582 7.0720486 6.7386697 7.405428 0.16870359       FALSE     1    -1\n75 7.672152 7.1567367 6.8163259 7.497148 0.17226202       FALSE     1    -1\n76 7.717722 7.2414248 6.8939523 7.588897 0.17583549       FALSE     1    -1\n77 7.763291 7.3261129 6.9715509 7.680675 0.17942310       FALSE     1    -1\n78 7.808861 7.4108010 7.0491231 7.772479 0.18302403       FALSE     1    -1\n79 7.854430 7.4954891 7.1266705 7.864308 0.18663749       FALSE     1    -1\n80 7.900000 7.5801772 7.2041946 7.956160 0.19026278       FALSE     1    -1\n    colour   fill linewidth linetype weight alpha\n1  #3366FF grey60         1        1      1   0.4\n2  #3366FF grey60         1        1      1   0.4\n3  #3366FF grey60         1        1      1   0.4\n4  #3366FF grey60         1        1      1   0.4\n5  #3366FF grey60         1        1      1   0.4\n6  #3366FF grey60         1        1      1   0.4\n7  #3366FF grey60         1        1      1   0.4\n8  #3366FF grey60         1        1      1   0.4\n9  #3366FF grey60         1        1      1   0.4\n10 #3366FF grey60         1        1      1   0.4\n11 #3366FF grey60         1        1      1   0.4\n12 #3366FF grey60         1        1      1   0.4\n13 #3366FF grey60         1        1      1   0.4\n14 #3366FF grey60         1        1      1   0.4\n15 #3366FF grey60         1        1      1   0.4\n16 #3366FF grey60         1        1      1   0.4\n17 #3366FF grey60         1        1      1   0.4\n18 #3366FF grey60         1        1      1   0.4\n19 #3366FF grey60         1        1      1   0.4\n20 #3366FF grey60         1        1      1   0.4\n21 #3366FF grey60         1        1      1   0.4\n22 #3366FF grey60         1        1      1   0.4\n23 #3366FF grey60         1        1      1   0.4\n24 #3366FF grey60         1        1      1   0.4\n25 #3366FF grey60         1        1      1   0.4\n26 #3366FF grey60         1        1      1   0.4\n27 #3366FF grey60         1        1      1   0.4\n28 #3366FF grey60         1        1      1   0.4\n29 #3366FF grey60         1        1      1   0.4\n30 #3366FF grey60         1        1      1   0.4\n31 #3366FF grey60         1        1      1   0.4\n32 #3366FF grey60         1        1      1   0.4\n33 #3366FF grey60         1        1      1   0.4\n34 #3366FF grey60         1        1      1   0.4\n35 #3366FF grey60         1        1      1   0.4\n36 #3366FF grey60         1        1      1   0.4\n37 #3366FF grey60         1        1      1   0.4\n38 #3366FF grey60         1        1      1   0.4\n39 #3366FF grey60         1        1      1   0.4\n40 #3366FF grey60         1        1      1   0.4\n41 #3366FF grey60         1        1      1   0.4\n42 #3366FF grey60         1        1      1   0.4\n43 #3366FF grey60         1        1      1   0.4\n44 #3366FF grey60         1        1      1   0.4\n45 #3366FF grey60         1        1      1   0.4\n46 #3366FF grey60         1        1      1   0.4\n47 #3366FF grey60         1        1      1   0.4\n48 #3366FF grey60         1        1      1   0.4\n49 #3366FF grey60         1        1      1   0.4\n50 #3366FF grey60         1        1      1   0.4\n51 #3366FF grey60         1        1      1   0.4\n52 #3366FF grey60         1        1      1   0.4\n53 #3366FF grey60         1        1      1   0.4\n54 #3366FF grey60         1        1      1   0.4\n55 #3366FF grey60         1        1      1   0.4\n56 #3366FF grey60         1        1      1   0.4\n57 #3366FF grey60         1        1      1   0.4\n58 #3366FF grey60         1        1      1   0.4\n59 #3366FF grey60         1        1      1   0.4\n60 #3366FF grey60         1        1      1   0.4\n61 #3366FF grey60         1        1      1   0.4\n62 #3366FF grey60         1        1      1   0.4\n63 #3366FF grey60         1        1      1   0.4\n64 #3366FF grey60         1        1      1   0.4\n65 #3366FF grey60         1        1      1   0.4\n66 #3366FF grey60         1        1      1   0.4\n67 #3366FF grey60         1        1      1   0.4\n68 #3366FF grey60         1        1      1   0.4\n69 #3366FF grey60         1        1      1   0.4\n70 #3366FF grey60         1        1      1   0.4\n71 #3366FF grey60         1        1      1   0.4\n72 #3366FF grey60         1        1      1   0.4\n73 #3366FF grey60         1        1      1   0.4\n74 #3366FF grey60         1        1      1   0.4\n75 #3366FF grey60         1        1      1   0.4\n76 #3366FF grey60         1        1      1   0.4\n77 #3366FF grey60         1        1      1   0.4\n78 #3366FF grey60         1        1      1   0.4\n79 #3366FF grey60         1        1      1   0.4\n80 #3366FF grey60         1        1      1   0.4\n\n\n\n\n\n\n ggplot(data = iris)+\ngeom_density(aes(x = Sepal.Length, fill = \"Sepal.Length\"))\n\n\n\n\n\n\n\nggplot(data = iris)+\ngeom_density(aes(x = Sepal.Length, fill = \"Sepal.Length\"))+\ngeom_density(aes(x = Sepal.Width, fill = \"Sepal.Width\"))\n\n\n\n\n\n\n\n\nggplot(data = iris)+\ngeom_density(aes(x = Sepal.Length, fill = \"Sepal.Length\"))+\ngeom_density(aes(x = Sepal.Width, fill = \"Sepal.Width\"))+\ngeom_density(aes(x = Petal.Width, fill = \"Petal.Width\"))\n\n\n\n\n\n\n\n\nggplot(data = iris)+\ngeom_density(aes(x = Sepal.Length, fill = \"Sepal.Length\"), alpha=0.4,color=NA)+\ngeom_density(aes(x = Sepal.Width, fill = \"Sepal.Width\"), alpha=0.4,color=NA)+\ngeom_density(aes(x = Petal.Width, fill = \"Petal.Width\"), alpha=0.4,color=NA)+\ngeom_density(aes(x = Petal.Length, fill = \"Petal.Length\"), alpha=0.4,color=NA)+\nlabs(x=\"cm\", y=\"Fréquence\")\n\n\n\n\n\n\n\n\n\nmy_df&lt;-iris %&gt;%\n  group_by(Species)%&gt;%\n  summarise(moyenne=mean(Sepal.Length, na.rm=TRUE), sd=sd(Sepal.Length, na.rm=TRUE))\n\nmy_df&lt;-as.data.frame(my_df)\n\nggplot(data = my_df, aes(Species, moyenne))+# scatter plot\n  geom_col(aes(color= Species, fill=Species))+\n  labs(x=\"Species\", y=\"Sepal.Length (mm)\")+\n  geom_errorbar(aes(ymin = moyenne-sd, ymax = moyenne+sd), width=0.2)\n\n\n\n\n\n\n\n\nggplot(data = iris, aes(Species, Sepal.Length))+ \n  geom_boxplot()+\n  labs(x=\"Species\", y=\"Sepal.Length (mm)\")+\n  theme_minimal()\n\n\n\n\n\n\n\nggplot(data = iris, aes(Species, Sepal.Length))+\n  geom_boxplot(aes(color=Species, fill=Species), alpha=0.4)+\n  labs(x=\"Species\", y=\"Sepal.Length (mm)\")+\n  theme_minimal()\n\n\n\n\n\n\n\n\nggplot(data = iris, aes(Species, Sepal.Length))+\n  geom_boxplot(aes(color=Species, fill=Species), alpha=0.4)+\n  geom_jitter(aes(colour = Species), position = position_jitter(0.07), cex = 2.2)+\n  labs(x=\"Species\", y=\"Sepal.Length (mm)\")+\n  theme_minimal()\n\n\n\n\n\n\n\n\nggplot(data=iris, aes(x=Species, y=Sepal.Length))+\ngeom_boxplot(aes(fill=Species,col=Species),alpha=0.6)+\nlabs(x=\"Species\",y=\"Sepal Length\", title=\"Iris Boxplot\")+\nstat_summary(fun=mean, geom=\"point\", shape=5, col=\"white\", size=3) \n\n\n\n\n\n\n\n\nNote density throughout contour lines\n\nggplot(data=iris,aes(x=Sepal.Width,y=Sepal.Length, color=Species))+ \ngeom_density2d()\n\n\n\n\n\n\n\nggplot(data=iris,aes(x=Sepal.Width,y=Sepal.Length, color=Species)) +\ngeom_point()+\ngeom_density2d()\n\n\n\n\n\n\n\nDensity across “bands”. Note:contour_var = “ndensity”: Normalise intensity to 1.\n\nggplot(data=iris,aes(x=Sepal.Width,y=Sepal.Length)) +\ngeom_point(cex=0.8)+\ngeom_density_2d_filled(alpha = 0.5,bins=5,contour_var = \"ndensity\")\n\n\n\n\n\nggplot(data=iris,aes(x=Sepal.Width,y=Sepal.Length)) +\ngeom_point(aes(col=Species),cex=0.5)+\ngeom_density_2d_filled(alpha = 0.7,contour_var = \"ndensity\", bins=15)\n\n\n\n\nSave your plot\n\npdf(\"yourfile.pdf\")\nggplot(data = iris, aes(Species, Sepal.Length))+\n  geom_boxplot(aes(color=Species, fill=Species), alpha=0.4)+\n  geom_jitter(aes(colour = Species), position = position_jitter(0.07), cex = 2.2)+\n  labs(x=\"Species\", y=\"Sepal.Length (mm)\")+\n  theme_minimal()\ndev.off()\n\nquartz_off_screen \n                2 \n\n\n\n\n\n\n\nFor this, we will use facet_wrap option on iris data\n\nggplot(data = iris, aes(Sepal.Length,Petal.Length))+\n  geom_point(aes(shape = Species))+\n  facet_wrap(~Species, scales = \"free\")\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nLibrary patchwork offers more adventage to custom your different panel. You can find here more information about patchwork packages\n\n\n\nlibrary(patchwork)\ng1&lt;-ggplot(data=iris, aes(x=Species, y=Sepal.Length))+\ngeom_boxplot(aes(fill=Species,col=Species),alpha=0.6)+\nlabs(x=\"Species\",y=\"Sepal Length\", title=\"Iris Boxplot\")+\nstat_summary(fun=mean, geom=\"point\", shape=5, col=\"white\", size=3) \n\ng2&lt;-ggplot(data=iris,aes(x=Sepal.Width,y=Sepal.Length)) +\ngeom_point(aes(col=Species),cex=0.5)+\ngeom_density_2d_filled(alpha = 0.7,contour_var = \"ndensity\", bins=15)\n\ng3&lt;-ggplot(data = my_df, aes(Species, moyenne))+# scatter plot\n  geom_col(aes(color= Species, fill=Species))+\n  labs(x=\"Species\", y=\"Sepal.Length (mm)\")+\n  geom_errorbar(aes(ymin = moyenne-sd, ymax = moyenne+sd), width=0.2)\n\n(g1|g2)/g3\n\n\n\n\n\nlibrary(patchwork)\ng1&lt;-ggplot(data=iris, aes(x=Species, y=Sepal.Length))+\n  geom_boxplot(aes(fill=Species,col=Species),alpha=0.6)+\n  labs(x=\"Species\",y=\"Sepal Length\", title=\"Iris Boxplot\")+\n  stat_summary(fun=mean, geom=\"point\", shape=5, col=\"white\", size=3)+\n  theme_bw()+\n  ggtitle(\"A\")\n\ng2&lt;-ggplot(data=iris,aes(x=Sepal.Width,y=Sepal.Length)) +\n  geom_point(aes(col=Species),cex=0.5)+\n  geom_density_2d_filled(alpha = 0.7,contour_var = \"ndensity\", bins=15)+\n  theme_bw()+\n  ggtitle(\"B\")\n\ng3&lt;-ggplot(data = my_df, aes(Species, moyenne))+# scatter plot\n  geom_col(aes(color= Species, fill=Species))+\n  labs(x=\"Species\", y=\"Sepal.Length (mm)\")+\n  geom_errorbar(aes(ymin = moyenne-sd, ymax = moyenne+sd), width=0.2)+\n  theme_bw()+\n  ggtitle(\"C\")\n\n(g1|g2)/g3\n\n\n\n\n\n\n\nIf not installed, you have to install it and load it\n\np4&lt;-ggplot(data = iris, aes(Species, Sepal.Length))+\n  geom_boxplot(aes(color=Species, fill=Species), alpha=0.4)+\n  geom_jitter(aes(colour = Species), position = position_jitter(0.07), cex = 2.2)+\n  labs(x=\"Species\", y=\"Sepal.Length (mm)\")+\n  theme_minimal()\n\nplotly::ggplotly(p4, height = 350, width=800)\n\n\n\n\n\nExo 1\n\nRead the data set mapfileFa.txt\nGive me the structure of the data set, and explore the data set. Dimension of the data set ? What kind of variable do you have?\nGive me the distribution Chlorophyl and Nanoeukaryote using ggplot and geom_boxplot() colored by the geography. Using the package patchwork (https://cran.r-project.org/web/packages/patchwork/vignettes/patchwork.html) build figure with these two on a same pages and save it as pdf\nAdd a variable into the data frame as the ratio between NT and PT. Build a scatter of the ratio NT/PT as a function sample name and sort by geography using facet_wrap function. Change x and y label as Sample Name and Ratio NR/TP. Give a title at your figure.\nGroup dataset by the geopgraphy ,calclulate the mean and the sd of the nbr of Crypto. Build a bar plot with mean and error bar (sd) colored according to the geography and save the plot\n\nSave figure as pdf\nFilter South data in a new data frame. Build a scatter plot, with size of shape = 3 and color = red. Add a trend curve.\nDo the the same for northern site."
  },
  {
    "objectID": "Graph.html#i-use-of-ggplot-packages-to-perform-smart-plot",
    "href": "Graph.html#i-use-of-ggplot-packages-to-perform-smart-plot",
    "title": "Graph",
    "section": "",
    "text": "ggplot2 is a powerfull packages to make a very smart graph “ready to use” for publication. gg means grammar and graph, a concept which describe a graph using grammar. This package belong to tidyverse according to “dplyr”. According to the ggplot2 concept, a graph can be divided into different basic parts:Plot = data + Aesthetics + Geometry\n\ndata : data frame\naesthetics : allows to indicate the x and y variables. It can also be used to control the color, size and shape of the points, etc…\ngeometry : corresponds to the type of graph (histogram, box plot, line plot, …..)\n\n\n\n\n\n\n# if not alraedy done load library ggplot2\nlibrary(ggplot2)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\ndata(iris)\nggplot(data = iris, aes(Sepal.Length, Sepal.Width))+ # scatter plot \n  geom_point()\n\n\n\n\n\n\n\n\nggplot(data = iris, aes(Sepal.Length, Sepal.Width))+ # scatter plot \n  geom_line()\n\n\n\n\n\n\n\n\n\n\n\n# Change size, color and shape in a scatter plot \nggplot(data = iris, aes(Sepal.Length, Sepal.Width))+ # scatter plot \n  geom_point(size=3, color =\"steelblue\", shape=21)  # shape is the same thing wiht classical plot on R\n\n\n\n\n\n\n\n\n\n\n# We can calorize and give a shape by month \nggplot(data = iris, aes(Sepal.Length, Sepal.Width))+ # scatter plot \n  geom_point(aes(color = Species, shape = Species)) # shape is the same thing with classical plot on R\n\n\n\n\n\n\n\nBe carefull alpha option is for transparency and ranged between 0 and 1\n\nggplot(data = iris, aes(Sepal.Width,Sepal.Length))+  \ngeom_point(aes(color = Petal.Width, shape = Species), size = 2,alpha=(0.8))\n\n\n\n\nWhat kind of conclusion we can give me with this kind of graph?\n\n\n\n\n\nggplot(data = iris, aes(Sepal.Width,Sepal.Length))+  \ngeom_point(aes(color = Petal.Width, shape = Species), size = 2,alpha=(0.8))+\nscale_color_gradient(low = \"yellow\", high = \"red\")\n\n\n\n\n\n\n\n# You can change manually color with la fonction scale_color_manual()\nggplot(data = iris, aes(Sepal.Length, Sepal.Width))+ # scatter plot \n geom_point(aes(color = Species, shape = Species))  +\n  scale_color_manual(values = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"))\n\n\n\n#You can store your plot in a variable to print later \np&lt;-ggplot(data = iris, aes(Sepal.Length, Sepal.Width))+ # scatter plot \n geom_point(aes(color = Species, shape = Species))  +\n  scale_color_manual(values = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"))+\n  theme_minimal()\n  \n\nprint(p)\n\n\n\n\nWhat do you see if you play the following command : names(p)?\n\n\n\n\n\n#To arrange the graph we can add some label and change the position of the legend\np + theme(legend.position = \"top\")\n\n\n\np + labs(color = \"Species\", shape= \"Sepcies\",\n  title = \"Sepal Length for each speices\",\n  subtitle = \"is a data frame with 150 cases (rows) and 5 variables\",\n  x = \"Sepal.Length (mm)\", y = \"Sepal.Width (mm)\"\n  )\n\n\n\n\n\n\n\n\np2&lt;-ggplot(data = iris, aes(Sepal.Length,Petal.Length))+ # scatter plot \n  geom_point(size=3, color =\"steelblue\") +\n  stat_smooth(method=lm, se=TRUE, na.rm=TRUE, show.legend = TRUE)\np2 + labs(x = \"Sepal.Length (mm)\", y = \"Pepal.Length (mm)\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nTo get data from the trend\n\nggplot_build(p2)$data[[2]]\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n          x         y      ymin     ymax         se flipped_aes PANEL group\n1  4.300000 0.8898184 0.5928870 1.186750 0.15025965       FALSE     1    -1\n2  4.345570 0.9745065 0.6843700 1.264643 0.14682115       FALSE     1    -1\n3  4.391139 1.0591946 0.7758049 1.342584 0.14340694       FALSE     1    -1\n4  4.436709 1.1438827 0.8671884 1.420577 0.14001881       FALSE     1    -1\n5  4.482278 1.2285708 0.9585165 1.498625 0.13665869       FALSE     1    -1\n6  4.527848 1.3132589 1.0497850 1.576733 0.13332869       FALSE     1    -1\n7  4.573418 1.3979469 1.1409895 1.654904 0.13003114       FALSE     1    -1\n8  4.618987 1.4826350 1.2321248 1.733145 0.12676857       FALSE     1    -1\n9  4.664557 1.5673231 1.3231856 1.811461 0.12354374       FALSE     1    -1\n10 4.710127 1.6520112 1.4141657 1.889857 0.12035969       FALSE     1    -1\n11 4.755696 1.7366993 1.5050587 1.968340 0.11721974       FALSE     1    -1\n12 4.801266 1.8213874 1.5958574 2.046917 0.11412754       FALSE     1    -1\n13 4.846835 1.9060755 1.6865538 2.125597 0.11108706       FALSE     1    -1\n14 4.892405 1.9907635 1.7771394 2.204388 0.10810268       FALSE     1    -1\n15 4.937975 2.0754516 1.8676047 2.283299 0.10517918       FALSE     1    -1\n16 4.983544 2.1601397 1.9579394 2.362340 0.10232176       FALSE     1    -1\n17 5.029114 2.2448278 2.0481322 2.441523 0.09953612       FALSE     1    -1\n18 5.074684 2.3295159 2.1381710 2.520861 0.09682845       FALSE     1    -1\n19 5.120253 2.4142040 2.2280424 2.600366 0.09420548       FALSE     1    -1\n20 5.165823 2.4988921 2.3177320 2.680052 0.09167449       FALSE     1    -1\n21 5.211392 2.5835801 2.4072245 2.759936 0.08924328       FALSE     1    -1\n22 5.256962 2.6682682 2.4965032 2.840033 0.08692025       FALSE     1    -1\n23 5.302532 2.7529563 2.5855505 2.920362 0.08471428       FALSE     1    -1\n24 5.348101 2.8376444 2.6743480 3.000941 0.08263476       FALSE     1    -1\n25 5.393671 2.9223325 2.7628763 3.081789 0.08069145       FALSE     1    -1\n26 5.439241 3.0070206 2.8511155 3.162926 0.07889444       FALSE     1    -1\n27 5.484810 3.0917086 2.9390454 3.244372 0.07725392       FALSE     1    -1\n28 5.530380 3.1763967 3.0266461 3.326147 0.07578006       FALSE     1    -1\n29 5.575949 3.2610848 3.1138978 3.408272 0.07448275       FALSE     1    -1\n30 5.621519 3.3457729 3.2007821 3.490764 0.07337136       FALSE     1    -1\n31 5.667089 3.4304610 3.2872821 3.573640 0.07245446       FALSE     1    -1\n32 5.712658 3.5151491 3.3733831 3.656915 0.07173948       FALSE     1    -1\n33 5.758228 3.5998372 3.4590730 3.740601 0.07123252       FALSE     1    -1\n34 5.803797 3.6845252 3.5443430 3.824707 0.07093803       FALSE     1    -1\n35 5.849367 3.7692133 3.6291879 3.909239 0.07085867       FALSE     1    -1\n36 5.894937 3.8539014 3.7136063 3.994197 0.07099515       FALSE     1    -1\n37 5.940506 3.9385895 3.7976006 4.079578 0.07134624       FALSE     1    -1\n38 5.986076 4.0232776 3.8811770 4.165378 0.07190879       FALSE     1    -1\n39 6.031646 4.1079657 3.9643453 4.251586 0.07267789       FALSE     1    -1\n40 6.077215 4.1926538 4.0471181 4.338189 0.07364708       FALSE     1    -1\n41 6.122785 4.2773418 4.1295109 4.425173 0.07480857       FALSE     1    -1\n42 6.168354 4.3620299 4.2115411 4.512519 0.07615357       FALSE     1    -1\n43 6.213924 4.4467180 4.2932276 4.600208 0.07767254       FALSE     1    -1\n44 6.259494 4.5314061 4.3745899 4.688222 0.07935550       FALSE     1    -1\n45 6.305063 4.6160942 4.4556484 4.776540 0.08119225       FALSE     1    -1\n46 6.350633 4.7007823 4.5364230 4.865141 0.08317259       FALSE     1    -1\n47 6.396203 4.7854704 4.6169337 4.954007 0.08528654       FALSE     1    -1\n48 6.441772 4.8701584 4.6971995 5.043117 0.08752440       FALSE     1    -1\n49 6.487342 4.9548465 4.7772387 5.132454 0.08987692       FALSE     1    -1\n50 6.532911 5.0395346 4.8570686 5.222001 0.09233535       FALSE     1    -1\n51 6.578481 5.1242227 4.9367056 5.311740 0.09489144       FALSE     1    -1\n52 6.624051 5.2089108 5.0161647 5.401657 0.09753752       FALSE     1    -1\n53 6.669620 5.2935989 5.0954600 5.491738 0.10026647       FALSE     1    -1\n54 6.715190 5.3782869 5.1746046 5.581969 0.10307170       FALSE     1    -1\n55 6.760759 5.4629750 5.2536105 5.672340 0.10594715       FALSE     1    -1\n56 6.806329 5.5476631 5.3324885 5.762838 0.10888727       FALSE     1    -1\n57 6.851899 5.6323512 5.4112489 5.853454 0.11188695       FALSE     1    -1\n58 6.897468 5.7170393 5.4899007 5.944178 0.11494153       FALSE     1    -1\n59 6.943038 5.8017274 5.5684525 6.035002 0.11804675       FALSE     1    -1\n60 6.988608 5.8864155 5.6469119 6.125919 0.12119872       FALSE     1    -1\n61 7.034177 5.9711035 5.7252860 6.216921 0.12439388       FALSE     1    -1\n62 7.079747 6.0557916 5.8035811 6.308002 0.12762899       FALSE     1    -1\n63 7.125316 6.1404797 5.8818031 6.399156 0.13090109       FALSE     1    -1\n64 7.170886 6.2251678 5.9599574 6.490378 0.13420747       FALSE     1    -1\n65 7.216456 6.3098559 6.0380488 6.581663 0.13754566       FALSE     1    -1\n66 7.262025 6.3945440 6.1160818 6.673006 0.14091339       FALSE     1    -1\n67 7.307595 6.4792321 6.1940606 6.764404 0.14430861       FALSE     1    -1\n68 7.353165 6.5639201 6.2719887 6.855852 0.14772942       FALSE     1    -1\n69 7.398734 6.6486082 6.3498697 6.947347 0.15117407       FALSE     1    -1\n70 7.444304 6.7332963 6.4277068 7.038886 0.15464098       FALSE     1    -1\n71 7.489873 6.8179844 6.5055028 7.130466 0.15812868       FALSE     1    -1\n72 7.535443 6.9026725 6.5832603 7.222085 0.16163582       FALSE     1    -1\n73 7.581013 6.9873606 6.6609818 7.313739 0.16516118       FALSE     1    -1\n74 7.626582 7.0720486 6.7386697 7.405428 0.16870359       FALSE     1    -1\n75 7.672152 7.1567367 6.8163259 7.497148 0.17226202       FALSE     1    -1\n76 7.717722 7.2414248 6.8939523 7.588897 0.17583549       FALSE     1    -1\n77 7.763291 7.3261129 6.9715509 7.680675 0.17942310       FALSE     1    -1\n78 7.808861 7.4108010 7.0491231 7.772479 0.18302403       FALSE     1    -1\n79 7.854430 7.4954891 7.1266705 7.864308 0.18663749       FALSE     1    -1\n80 7.900000 7.5801772 7.2041946 7.956160 0.19026278       FALSE     1    -1\n    colour   fill linewidth linetype weight alpha\n1  #3366FF grey60         1        1      1   0.4\n2  #3366FF grey60         1        1      1   0.4\n3  #3366FF grey60         1        1      1   0.4\n4  #3366FF grey60         1        1      1   0.4\n5  #3366FF grey60         1        1      1   0.4\n6  #3366FF grey60         1        1      1   0.4\n7  #3366FF grey60         1        1      1   0.4\n8  #3366FF grey60         1        1      1   0.4\n9  #3366FF grey60         1        1      1   0.4\n10 #3366FF grey60         1        1      1   0.4\n11 #3366FF grey60         1        1      1   0.4\n12 #3366FF grey60         1        1      1   0.4\n13 #3366FF grey60         1        1      1   0.4\n14 #3366FF grey60         1        1      1   0.4\n15 #3366FF grey60         1        1      1   0.4\n16 #3366FF grey60         1        1      1   0.4\n17 #3366FF grey60         1        1      1   0.4\n18 #3366FF grey60         1        1      1   0.4\n19 #3366FF grey60         1        1      1   0.4\n20 #3366FF grey60         1        1      1   0.4\n21 #3366FF grey60         1        1      1   0.4\n22 #3366FF grey60         1        1      1   0.4\n23 #3366FF grey60         1        1      1   0.4\n24 #3366FF grey60         1        1      1   0.4\n25 #3366FF grey60         1        1      1   0.4\n26 #3366FF grey60         1        1      1   0.4\n27 #3366FF grey60         1        1      1   0.4\n28 #3366FF grey60         1        1      1   0.4\n29 #3366FF grey60         1        1      1   0.4\n30 #3366FF grey60         1        1      1   0.4\n31 #3366FF grey60         1        1      1   0.4\n32 #3366FF grey60         1        1      1   0.4\n33 #3366FF grey60         1        1      1   0.4\n34 #3366FF grey60         1        1      1   0.4\n35 #3366FF grey60         1        1      1   0.4\n36 #3366FF grey60         1        1      1   0.4\n37 #3366FF grey60         1        1      1   0.4\n38 #3366FF grey60         1        1      1   0.4\n39 #3366FF grey60         1        1      1   0.4\n40 #3366FF grey60         1        1      1   0.4\n41 #3366FF grey60         1        1      1   0.4\n42 #3366FF grey60         1        1      1   0.4\n43 #3366FF grey60         1        1      1   0.4\n44 #3366FF grey60         1        1      1   0.4\n45 #3366FF grey60         1        1      1   0.4\n46 #3366FF grey60         1        1      1   0.4\n47 #3366FF grey60         1        1      1   0.4\n48 #3366FF grey60         1        1      1   0.4\n49 #3366FF grey60         1        1      1   0.4\n50 #3366FF grey60         1        1      1   0.4\n51 #3366FF grey60         1        1      1   0.4\n52 #3366FF grey60         1        1      1   0.4\n53 #3366FF grey60         1        1      1   0.4\n54 #3366FF grey60         1        1      1   0.4\n55 #3366FF grey60         1        1      1   0.4\n56 #3366FF grey60         1        1      1   0.4\n57 #3366FF grey60         1        1      1   0.4\n58 #3366FF grey60         1        1      1   0.4\n59 #3366FF grey60         1        1      1   0.4\n60 #3366FF grey60         1        1      1   0.4\n61 #3366FF grey60         1        1      1   0.4\n62 #3366FF grey60         1        1      1   0.4\n63 #3366FF grey60         1        1      1   0.4\n64 #3366FF grey60         1        1      1   0.4\n65 #3366FF grey60         1        1      1   0.4\n66 #3366FF grey60         1        1      1   0.4\n67 #3366FF grey60         1        1      1   0.4\n68 #3366FF grey60         1        1      1   0.4\n69 #3366FF grey60         1        1      1   0.4\n70 #3366FF grey60         1        1      1   0.4\n71 #3366FF grey60         1        1      1   0.4\n72 #3366FF grey60         1        1      1   0.4\n73 #3366FF grey60         1        1      1   0.4\n74 #3366FF grey60         1        1      1   0.4\n75 #3366FF grey60         1        1      1   0.4\n76 #3366FF grey60         1        1      1   0.4\n77 #3366FF grey60         1        1      1   0.4\n78 #3366FF grey60         1        1      1   0.4\n79 #3366FF grey60         1        1      1   0.4\n80 #3366FF grey60         1        1      1   0.4\n\n\n\n\n\n\n ggplot(data = iris)+\ngeom_density(aes(x = Sepal.Length, fill = \"Sepal.Length\"))\n\n\n\n\n\n\n\nggplot(data = iris)+\ngeom_density(aes(x = Sepal.Length, fill = \"Sepal.Length\"))+\ngeom_density(aes(x = Sepal.Width, fill = \"Sepal.Width\"))\n\n\n\n\n\n\n\n\nggplot(data = iris)+\ngeom_density(aes(x = Sepal.Length, fill = \"Sepal.Length\"))+\ngeom_density(aes(x = Sepal.Width, fill = \"Sepal.Width\"))+\ngeom_density(aes(x = Petal.Width, fill = \"Petal.Width\"))\n\n\n\n\n\n\n\n\nggplot(data = iris)+\ngeom_density(aes(x = Sepal.Length, fill = \"Sepal.Length\"), alpha=0.4,color=NA)+\ngeom_density(aes(x = Sepal.Width, fill = \"Sepal.Width\"), alpha=0.4,color=NA)+\ngeom_density(aes(x = Petal.Width, fill = \"Petal.Width\"), alpha=0.4,color=NA)+\ngeom_density(aes(x = Petal.Length, fill = \"Petal.Length\"), alpha=0.4,color=NA)+\nlabs(x=\"cm\", y=\"Fréquence\")\n\n\n\n\n\n\n\n\n\nmy_df&lt;-iris %&gt;%\n  group_by(Species)%&gt;%\n  summarise(moyenne=mean(Sepal.Length, na.rm=TRUE), sd=sd(Sepal.Length, na.rm=TRUE))\n\nmy_df&lt;-as.data.frame(my_df)\n\nggplot(data = my_df, aes(Species, moyenne))+# scatter plot\n  geom_col(aes(color= Species, fill=Species))+\n  labs(x=\"Species\", y=\"Sepal.Length (mm)\")+\n  geom_errorbar(aes(ymin = moyenne-sd, ymax = moyenne+sd), width=0.2)\n\n\n\n\n\n\n\n\nggplot(data = iris, aes(Species, Sepal.Length))+ \n  geom_boxplot()+\n  labs(x=\"Species\", y=\"Sepal.Length (mm)\")+\n  theme_minimal()\n\n\n\n\n\n\n\nggplot(data = iris, aes(Species, Sepal.Length))+\n  geom_boxplot(aes(color=Species, fill=Species), alpha=0.4)+\n  labs(x=\"Species\", y=\"Sepal.Length (mm)\")+\n  theme_minimal()\n\n\n\n\n\n\n\n\nggplot(data = iris, aes(Species, Sepal.Length))+\n  geom_boxplot(aes(color=Species, fill=Species), alpha=0.4)+\n  geom_jitter(aes(colour = Species), position = position_jitter(0.07), cex = 2.2)+\n  labs(x=\"Species\", y=\"Sepal.Length (mm)\")+\n  theme_minimal()\n\n\n\n\n\n\n\n\nggplot(data=iris, aes(x=Species, y=Sepal.Length))+\ngeom_boxplot(aes(fill=Species,col=Species),alpha=0.6)+\nlabs(x=\"Species\",y=\"Sepal Length\", title=\"Iris Boxplot\")+\nstat_summary(fun=mean, geom=\"point\", shape=5, col=\"white\", size=3) \n\n\n\n\n\n\n\n\nNote density throughout contour lines\n\nggplot(data=iris,aes(x=Sepal.Width,y=Sepal.Length, color=Species))+ \ngeom_density2d()\n\n\n\n\n\n\n\nggplot(data=iris,aes(x=Sepal.Width,y=Sepal.Length, color=Species)) +\ngeom_point()+\ngeom_density2d()\n\n\n\n\n\n\n\nDensity across “bands”. Note:contour_var = “ndensity”: Normalise intensity to 1.\n\nggplot(data=iris,aes(x=Sepal.Width,y=Sepal.Length)) +\ngeom_point(cex=0.8)+\ngeom_density_2d_filled(alpha = 0.5,bins=5,contour_var = \"ndensity\")\n\n\n\n\n\nggplot(data=iris,aes(x=Sepal.Width,y=Sepal.Length)) +\ngeom_point(aes(col=Species),cex=0.5)+\ngeom_density_2d_filled(alpha = 0.7,contour_var = \"ndensity\", bins=15)\n\n\n\n\nSave your plot\n\npdf(\"yourfile.pdf\")\nggplot(data = iris, aes(Species, Sepal.Length))+\n  geom_boxplot(aes(color=Species, fill=Species), alpha=0.4)+\n  geom_jitter(aes(colour = Species), position = position_jitter(0.07), cex = 2.2)+\n  labs(x=\"Species\", y=\"Sepal.Length (mm)\")+\n  theme_minimal()\ndev.off()\n\nquartz_off_screen \n                2 \n\n\n\n\n\n\n\nFor this, we will use facet_wrap option on iris data\n\nggplot(data = iris, aes(Sepal.Length,Petal.Length))+\n  geom_point(aes(shape = Species))+\n  facet_wrap(~Species, scales = \"free\")\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nLibrary patchwork offers more adventage to custom your different panel. You can find here more information about patchwork packages\n\n\n\nlibrary(patchwork)\ng1&lt;-ggplot(data=iris, aes(x=Species, y=Sepal.Length))+\ngeom_boxplot(aes(fill=Species,col=Species),alpha=0.6)+\nlabs(x=\"Species\",y=\"Sepal Length\", title=\"Iris Boxplot\")+\nstat_summary(fun=mean, geom=\"point\", shape=5, col=\"white\", size=3) \n\ng2&lt;-ggplot(data=iris,aes(x=Sepal.Width,y=Sepal.Length)) +\ngeom_point(aes(col=Species),cex=0.5)+\ngeom_density_2d_filled(alpha = 0.7,contour_var = \"ndensity\", bins=15)\n\ng3&lt;-ggplot(data = my_df, aes(Species, moyenne))+# scatter plot\n  geom_col(aes(color= Species, fill=Species))+\n  labs(x=\"Species\", y=\"Sepal.Length (mm)\")+\n  geom_errorbar(aes(ymin = moyenne-sd, ymax = moyenne+sd), width=0.2)\n\n(g1|g2)/g3\n\n\n\n\n\nlibrary(patchwork)\ng1&lt;-ggplot(data=iris, aes(x=Species, y=Sepal.Length))+\n  geom_boxplot(aes(fill=Species,col=Species),alpha=0.6)+\n  labs(x=\"Species\",y=\"Sepal Length\", title=\"Iris Boxplot\")+\n  stat_summary(fun=mean, geom=\"point\", shape=5, col=\"white\", size=3)+\n  theme_bw()+\n  ggtitle(\"A\")\n\ng2&lt;-ggplot(data=iris,aes(x=Sepal.Width,y=Sepal.Length)) +\n  geom_point(aes(col=Species),cex=0.5)+\n  geom_density_2d_filled(alpha = 0.7,contour_var = \"ndensity\", bins=15)+\n  theme_bw()+\n  ggtitle(\"B\")\n\ng3&lt;-ggplot(data = my_df, aes(Species, moyenne))+# scatter plot\n  geom_col(aes(color= Species, fill=Species))+\n  labs(x=\"Species\", y=\"Sepal.Length (mm)\")+\n  geom_errorbar(aes(ymin = moyenne-sd, ymax = moyenne+sd), width=0.2)+\n  theme_bw()+\n  ggtitle(\"C\")\n\n(g1|g2)/g3\n\n\n\n\n\n\n\nIf not installed, you have to install it and load it\n\np4&lt;-ggplot(data = iris, aes(Species, Sepal.Length))+\n  geom_boxplot(aes(color=Species, fill=Species), alpha=0.4)+\n  geom_jitter(aes(colour = Species), position = position_jitter(0.07), cex = 2.2)+\n  labs(x=\"Species\", y=\"Sepal.Length (mm)\")+\n  theme_minimal()\n\nplotly::ggplotly(p4, height = 350, width=800)\n\n\n\n\n\nExo 1\n\nRead the data set mapfileFa.txt\nGive me the structure of the data set, and explore the data set. Dimension of the data set ? What kind of variable do you have?\nGive me the distribution Chlorophyl and Nanoeukaryote using ggplot and geom_boxplot() colored by the geography. Using the package patchwork (https://cran.r-project.org/web/packages/patchwork/vignettes/patchwork.html) build figure with these two on a same pages and save it as pdf\nAdd a variable into the data frame as the ratio between NT and PT. Build a scatter of the ratio NT/PT as a function sample name and sort by geography using facet_wrap function. Change x and y label as Sample Name and Ratio NR/TP. Give a title at your figure.\nGroup dataset by the geopgraphy ,calclulate the mean and the sd of the nbr of Crypto. Build a bar plot with mean and error bar (sd) colored according to the geography and save the plot\n\nSave figure as pdf\nFilter South data in a new data frame. Build a scatter plot, with size of shape = 3 and color = red. Add a trend curve.\nDo the the same for northern site."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "FormationR",
    "section": "",
    "text": "Welcome on the R training provided by OMICS platform and MIO"
  },
  {
    "objectID": "index.html#schedule",
    "href": "index.html#schedule",
    "title": "FormationR",
    "section": "Schedule",
    "text": "Schedule\n\nDAY1 :\n\nRstudio environment and R language course\nPractical 1: R basics: Vectors, Tables, dataframe, manipulations, descriptive statistics, Rmarkdown\n\nDAY2\n\nEnd of Practical 1\nGraphical representation of biological data & management of parameters type/colour/shape/…\n\nDAY3\n\nPractical 2 Graphical representation of results\n\nDAY4\n\nLectures and practical work: Inferential statistics (Anova, Kruskall, Wilcoxon, regression, correlation, r, R2, adjusted p-value, etc.)\n\nDay 5\n\nGlobal test - Validation of prior learning\n\nUseful documents\nIn this section you can find some cheatsheet for some important packages :\n\ndplyr\nggplo2\nrmarkdown"
  },
  {
    "objectID": "about.html#organisation-committee-and-intervenants",
    "href": "about.html#organisation-committee-and-intervenants",
    "title": "About",
    "section": "Organisation committee and intervenants",
    "text": "Organisation committee and intervenants\nLaurie Casalot\nFabrice Armougom\nMarc Garel\nPauline Le Coq"
  },
  {
    "objectID": "Statistics.html",
    "href": "Statistics.html",
    "title": "Statistics",
    "section": "",
    "text": "#libraries\nlibrary(ggplot2)\nlibrary(base)\nlibrary(psych)\nlibrary(dplyr)\nlibrary(stats)\nlibrary(FSA)\nlibrary(ggpubr)\nlibrary(corrplot)\nlibrary(ggpmisc)\nlibrary(graphics)\nlibrary(broom)\nlibrary(dplyr)\nlibrary(tidyr)\n\n\n#Function indice_normality\nindices_normality &lt;- function(rich, nrow, ncol) {\n\n  ### p-value &lt; 0.05 means data failed normality test\n\n  par(mfrow = c(nrow, ncol))\n\n  for (i in names(rich)) {\n    shap &lt;- shapiro.test(rich[, i])\n    qqnorm(rich[, i], main = i, sub = shap$p.value)\n    qqline(rich[, i])\n  }\n\n  par(mfrow = c(1, 1))\n}\n############\n#Function multiple panel with linear regression & r values\nregression_line = function(x,y, ...){\n    points(x,y,...)\n    linear_regression = lm(y~x)\n    linear_regression_line = abline(linear_regression, col=\"red\")\n}\n###########\npanel.cor &lt;- function(x, y, digits = 2, prefix = \"\", cex.cor, ...) {\n  usr &lt;- par(\"usr\")\n  on.exit(par(usr))\n  par(usr = c(0, 1, 0, 1))\n  r &lt;- abs(cor(x, y, use = \"complete.obs\"))\n  txt &lt;- format(c(r, 0.123456789), digits = digits)[1]\n  txt &lt;- paste(prefix, txt, sep = \"\")\n  if (missing(cex.cor)) cex.cor &lt;- 0.8/strwidth(txt)\n  text(0.5, 0.5, txt, cex =  cex.cor * (1 + r) / 2)\n}"
  },
  {
    "objectID": "Statistics.html#load-libraries-functions",
    "href": "Statistics.html#load-libraries-functions",
    "title": "Statistics",
    "section": "",
    "text": "#libraries\nlibrary(ggplot2)\nlibrary(base)\nlibrary(psych)\nlibrary(dplyr)\nlibrary(stats)\nlibrary(FSA)\nlibrary(ggpubr)\nlibrary(corrplot)\nlibrary(ggpmisc)\nlibrary(graphics)\nlibrary(broom)\nlibrary(dplyr)\nlibrary(tidyr)\n\n\n#Function indice_normality\nindices_normality &lt;- function(rich, nrow, ncol) {\n\n  ### p-value &lt; 0.05 means data failed normality test\n\n  par(mfrow = c(nrow, ncol))\n\n  for (i in names(rich)) {\n    shap &lt;- shapiro.test(rich[, i])\n    qqnorm(rich[, i], main = i, sub = shap$p.value)\n    qqline(rich[, i])\n  }\n\n  par(mfrow = c(1, 1))\n}\n############\n#Function multiple panel with linear regression & r values\nregression_line = function(x,y, ...){\n    points(x,y,...)\n    linear_regression = lm(y~x)\n    linear_regression_line = abline(linear_regression, col=\"red\")\n}\n###########\npanel.cor &lt;- function(x, y, digits = 2, prefix = \"\", cex.cor, ...) {\n  usr &lt;- par(\"usr\")\n  on.exit(par(usr))\n  par(usr = c(0, 1, 0, 1))\n  r &lt;- abs(cor(x, y, use = \"complete.obs\"))\n  txt &lt;- format(c(r, 0.123456789), digits = digits)[1]\n  txt &lt;- paste(prefix, txt, sep = \"\")\n  if (missing(cex.cor)) cex.cor &lt;- 0.8/strwidth(txt)\n  text(0.5, 0.5, txt, cex =  cex.cor * (1 + r) / 2)\n}"
  },
  {
    "objectID": "Statistics.html#i--manipulate-a-data-table",
    "href": "Statistics.html#i--manipulate-a-data-table",
    "title": "Statistics",
    "section": "I- Manipulate a data table",
    "text": "I- Manipulate a data table\n\na/ Read a table containing data\n\n\nalldata = read.table(file =\"./data/data_explore.txt\",\n                      check.names = TRUE,\n                      header = TRUE, \n                      sep = \"\\t\",\n                      row.names = 1)\n\n\n#see\nalldata\n\n    Description Geo groupe SiOH4   NO2   NO3   NH4   PO4    NT    PT  Chla\nU1H       USA_H USA      A  1690 2.324 0.083 0.856 0.467 0.115 9.539 4.138\nU2H       USA_H USA      A   115 1.813 0.256 0.889 0.324 0.132 9.946 3.565\nU3H       USA_H USA      A   395 2.592 0.105 1.125 0.328 0.067 9.378 3.391\nU4H       USA_H USA      A   395 2.381 0.231 0.706 0.450 0.109 8.817 3.345\nU5F       USA_F USA      B   200 1.656 0.098 0.794 0.367 0.095 7.847 2.520\nU6F       USA_F USA      B   235 2.457 0.099 1.087 0.349 0.137 8.689 3.129\nU7F       USA_F USA      B   235 2.457 0.099 1.087 0.349 0.137 8.689 3.129\nU8F       USA_F USA      B  1355 2.028 0.103 1.135 0.216 0.128 8.623 3.137\nE1H        EU_H  EU      C   945 2.669 0.136 0.785 0.267 0.114 9.146 3.062\nE2H        EU_H  EU      C  1295 2.206 0.249 0.768 0.629 0.236 9.013 3.455\nE3H        EU_H  EU      C  1300 3.004 0.251 0.727 0.653 0.266 8.776 3.230\nE4H        EU_H  EU      C  1600 3.016 0.257 0.695 0.491 0.176 8.968 4.116\nE5F        EU_F  EU      D  1355 1.198 0.165 1.099 0.432 0.180 8.256 3.182\nE6F        EU_F  EU      D  1590 3.868 0.253 0.567 0.533 0.169 8.395 3.126\nE7F        EU_F  EU      D  2265 3.639 0.255 0.658 0.665 0.247 8.991 3.843\nE8F        EU_F  EU      D  1180 3.910 0.107 0.472 0.490 0.134 8.954 4.042\nE9F        EU_F  EU      D  1545 3.607 0.139 0.444 0.373 0.167 9.817 3.689\n         T       S Sigma_t observed   shannon evenness dominance_relative\nU1H 0.0182 23.0308 38.9967  26.9631 0.9447863 3.146480          0.8780420\nU2H 0.0000 22.7338 37.6204  26.0046 0.9477924 3.177766          0.8937989\nU3H 0.0000 22.6824 37.6627  26.0521 0.9577758 3.408022          0.9060997\nU4H 0.0000 22.6854 37.6176  26.0137 0.9414576 3.112066          0.8684385\nU5F 0.0000 22.5610 37.5960  26.0332 0.9491313 3.246802          0.8925706\nU6F 0.0000 18.8515 37.4542  26.9415 0.9570249 3.350694          0.9083230\nU7F 0.0000 18.8515 37.4542  26.9415 0.9363446 3.097474          0.8396788\nU8F 0.0102 24.1905 38.3192  26.1037 0.9271578 2.978541          0.8594252\nE1H 0.0000 24.1789 38.3213  26.1065 0.9253250 2.993341          0.8560944\nE2H 0.0000 22.0197 39.0877  27.3241 0.9439556 3.213508          0.8653415\nE3H 0.0134 22.0515 39.0884  27.3151 0.8247810 2.440971          0.7325395\nE4H 0.0000 23.6669 38.9699  26.7536 0.9435901 3.157702          0.8811735\nE5F 0.0000 23.6814 38.9708  26.7488 0.9488744 3.278296          0.8663140\nE6F 0.0000 23.1236 39.0054  26.9423 0.9452117 3.108474          0.8890226\nE7F 0.0132 23.3147 38.9885  26.8713 0.9517578 3.307644          0.9028494\nE8F 0.0172 22.6306 38.9094  27.0131 0.9443038 3.105908          0.8667202\nE9F 0.0062 22.9545 38.7777  26.8172 0.9487545 3.180393          0.9095912\n           NRI         NTI          PD        X\nU1H 0.10274791 -1.72903786 -1.62669669 3.508045\nU2H 0.10274791  1.12496864 -0.75543498 3.330466\nU3H 0.09677419 -0.23029299 -0.69141166 3.688595\nU4H 0.10991637 -2.48017258 -0.64705490 3.401944\nU5F 0.10991637 -0.17940416 -0.67857965 3.430623\nU6F 0.08721625 -0.40633803  0.05055793 3.293266\nU7F 0.14336918  1.79668405 -0.84513858 3.428512\nU8F 0.16606930  0.12915148  0.12211753 2.969649\nE1H 0.18876941 -0.07458097  1.95798975 2.451799\nE2H 0.13620072  0.17114822  1.11902329 3.127781\nE3H 0.38351254  2.65479470 -0.01038346 2.422910\nE4H 0.13022700 -1.42798211 -0.64181960 3.157211\nE5F 0.10633214 -2.49590494  0.79285403 3.433528\nE6F 0.09438471 -0.10962187  0.81104335 2.921706\nE7F 0.09677419 -1.21112926  0.51096388 3.282069\nE8F 0.09438471 -0.04833770  0.26352612 2.879671\nE9F 0.10394265  0.50404786  2.43432750 2.430342\n\n\n1- Can you display only the column NO3 of the table?\n2- Can you display the row names of the table? (means U1H, U2H etc) \n3- Can you select and display any 3 columns of the table? \n\nb/ Select a subset from data table \n\n\n#Keep only data that correspond to \"EU\" in the Geo column\nsubgroupEU = subset(alldata, Geo==\"EU\")\n#See \nsubgroupEU\n\n    Description Geo groupe SiOH4   NO2   NO3   NH4   PO4    NT    PT  Chla\nE1H        EU_H  EU      C   945 2.669 0.136 0.785 0.267 0.114 9.146 3.062\nE2H        EU_H  EU      C  1295 2.206 0.249 0.768 0.629 0.236 9.013 3.455\nE3H        EU_H  EU      C  1300 3.004 0.251 0.727 0.653 0.266 8.776 3.230\nE4H        EU_H  EU      C  1600 3.016 0.257 0.695 0.491 0.176 8.968 4.116\nE5F        EU_F  EU      D  1355 1.198 0.165 1.099 0.432 0.180 8.256 3.182\nE6F        EU_F  EU      D  1590 3.868 0.253 0.567 0.533 0.169 8.395 3.126\nE7F        EU_F  EU      D  2265 3.639 0.255 0.658 0.665 0.247 8.991 3.843\nE8F        EU_F  EU      D  1180 3.910 0.107 0.472 0.490 0.134 8.954 4.042\nE9F        EU_F  EU      D  1545 3.607 0.139 0.444 0.373 0.167 9.817 3.689\n         T       S Sigma_t observed   shannon evenness dominance_relative\nE1H 0.0000 24.1789 38.3213  26.1065 0.9253250 2.993341          0.8560944\nE2H 0.0000 22.0197 39.0877  27.3241 0.9439556 3.213508          0.8653415\nE3H 0.0134 22.0515 39.0884  27.3151 0.8247810 2.440971          0.7325395\nE4H 0.0000 23.6669 38.9699  26.7536 0.9435901 3.157702          0.8811735\nE5F 0.0000 23.6814 38.9708  26.7488 0.9488744 3.278296          0.8663140\nE6F 0.0000 23.1236 39.0054  26.9423 0.9452117 3.108474          0.8890226\nE7F 0.0132 23.3147 38.9885  26.8713 0.9517578 3.307644          0.9028494\nE8F 0.0172 22.6306 38.9094  27.0131 0.9443038 3.105908          0.8667202\nE9F 0.0062 22.9545 38.7777  26.8172 0.9487545 3.180393          0.9095912\n           NRI         NTI          PD        X\nE1H 0.18876941 -0.07458097  1.95798975 2.451799\nE2H 0.13620072  0.17114822  1.11902329 3.127781\nE3H 0.38351254  2.65479470 -0.01038346 2.422910\nE4H 0.13022700 -1.42798211 -0.64181960 3.157211\nE5F 0.10633214 -2.49590494  0.79285403 3.433528\nE6F 0.09438471 -0.10962187  0.81104335 2.921706\nE7F 0.09677419 -1.21112926  0.51096388 3.282069\nE8F 0.09438471 -0.04833770  0.26352612 2.879671\nE9F 0.10394265  0.50404786  2.43432750 2.430342\n\n\n\n#Keep only data that correspond to group A & B in the group column\nsubgroupAB = subset(alldata, groupe==\"A\" | groupe==\"B\")\n#See\nsubgroupAB\n\n    Description Geo groupe SiOH4   NO2   NO3   NH4   PO4    NT    PT  Chla\nU1H       USA_H USA      A  1690 2.324 0.083 0.856 0.467 0.115 9.539 4.138\nU2H       USA_H USA      A   115 1.813 0.256 0.889 0.324 0.132 9.946 3.565\nU3H       USA_H USA      A   395 2.592 0.105 1.125 0.328 0.067 9.378 3.391\nU4H       USA_H USA      A   395 2.381 0.231 0.706 0.450 0.109 8.817 3.345\nU5F       USA_F USA      B   200 1.656 0.098 0.794 0.367 0.095 7.847 2.520\nU6F       USA_F USA      B   235 2.457 0.099 1.087 0.349 0.137 8.689 3.129\nU7F       USA_F USA      B   235 2.457 0.099 1.087 0.349 0.137 8.689 3.129\nU8F       USA_F USA      B  1355 2.028 0.103 1.135 0.216 0.128 8.623 3.137\n         T       S Sigma_t observed   shannon evenness dominance_relative\nU1H 0.0182 23.0308 38.9967  26.9631 0.9447863 3.146480          0.8780420\nU2H 0.0000 22.7338 37.6204  26.0046 0.9477924 3.177766          0.8937989\nU3H 0.0000 22.6824 37.6627  26.0521 0.9577758 3.408022          0.9060997\nU4H 0.0000 22.6854 37.6176  26.0137 0.9414576 3.112066          0.8684385\nU5F 0.0000 22.5610 37.5960  26.0332 0.9491313 3.246802          0.8925706\nU6F 0.0000 18.8515 37.4542  26.9415 0.9570249 3.350694          0.9083230\nU7F 0.0000 18.8515 37.4542  26.9415 0.9363446 3.097474          0.8396788\nU8F 0.0102 24.1905 38.3192  26.1037 0.9271578 2.978541          0.8594252\n           NRI        NTI          PD        X\nU1H 0.10274791 -1.7290379 -1.62669669 3.508045\nU2H 0.10274791  1.1249686 -0.75543498 3.330466\nU3H 0.09677419 -0.2302930 -0.69141166 3.688595\nU4H 0.10991637 -2.4801726 -0.64705490 3.401944\nU5F 0.10991637 -0.1794042 -0.67857965 3.430623\nU6F 0.08721625 -0.4063380  0.05055793 3.293266\nU7F 0.14336918  1.7966841 -0.84513858 3.428512\nU8F 0.16606930  0.1291515  0.12211753 2.969649\n\n\n\nc/ How to Add a new variable after loading table \nYou forgot to add a variable to your table & you have already loaded your table in R session…how to manage this? \n\n\n# FIRST create a dataframe with a vector with  values of your new variable\nmydataframe = data.frame(MYNEWVAR = c(\"sediment\", \"mer\", \"sediment\",\n                                       \"trap\", \"mer\", \"mer\",\n                                       \"trap\", \"trap\", \"trap\",\n                                       \"sediment\", \"mer\", \"mer\",\n                                       \"mer\", \"trap\", \"trap\",\n                                       \"mer\", \"mer\"))\n\n#Add rownames=samples names\nrow.names(mydataframe) = c(\"U1H\", \"U2H\", \"U5F\",\n                            \"U6F\", \"U3H\", \"U7F\",\n                            \"U4H\", \"U8F\", \"E2H\",\n                            \"E3H\", \"E5F\", \"E1H\",\n                            \"E7F\", \"E6F\", \"E4H\",\n                            \"E9F\", \"E8F\")\n\n# See & notice that order of sample names is not the same as in mesdata\nmydataframe\n\n    MYNEWVAR\nU1H sediment\nU2H      mer\nU5F sediment\nU6F     trap\nU3H      mer\nU7F      mer\nU4H     trap\nU8F     trap\nE2H     trap\nE3H sediment\nE5F      mer\nE1H      mer\nE7F      mer\nE6F     trap\nE4H     trap\nE9F      mer\nE8F      mer\n\n\n\nMerge the two dataframes!\n\n\n#Option \"by=\" the way that you want to merge... here looking for same row.names between the two dataframe\n# in mydataframe and mesdata\nalldata = merge(alldata,mydataframe, by=\"row.names\")\n\n#check that it works\nalldata\n\n   Row.names Description Geo groupe SiOH4   NO2   NO3   NH4   PO4    NT    PT\n1        E1H        EU_H  EU      C   945 2.669 0.136 0.785 0.267 0.114 9.146\n2        E2H        EU_H  EU      C  1295 2.206 0.249 0.768 0.629 0.236 9.013\n3        E3H        EU_H  EU      C  1300 3.004 0.251 0.727 0.653 0.266 8.776\n4        E4H        EU_H  EU      C  1600 3.016 0.257 0.695 0.491 0.176 8.968\n5        E5F        EU_F  EU      D  1355 1.198 0.165 1.099 0.432 0.180 8.256\n6        E6F        EU_F  EU      D  1590 3.868 0.253 0.567 0.533 0.169 8.395\n7        E7F        EU_F  EU      D  2265 3.639 0.255 0.658 0.665 0.247 8.991\n8        E8F        EU_F  EU      D  1180 3.910 0.107 0.472 0.490 0.134 8.954\n9        E9F        EU_F  EU      D  1545 3.607 0.139 0.444 0.373 0.167 9.817\n10       U1H       USA_H USA      A  1690 2.324 0.083 0.856 0.467 0.115 9.539\n11       U2H       USA_H USA      A   115 1.813 0.256 0.889 0.324 0.132 9.946\n12       U3H       USA_H USA      A   395 2.592 0.105 1.125 0.328 0.067 9.378\n13       U4H       USA_H USA      A   395 2.381 0.231 0.706 0.450 0.109 8.817\n14       U5F       USA_F USA      B   200 1.656 0.098 0.794 0.367 0.095 7.847\n15       U6F       USA_F USA      B   235 2.457 0.099 1.087 0.349 0.137 8.689\n16       U7F       USA_F USA      B   235 2.457 0.099 1.087 0.349 0.137 8.689\n17       U8F       USA_F USA      B  1355 2.028 0.103 1.135 0.216 0.128 8.623\n    Chla      T       S Sigma_t observed   shannon evenness dominance_relative\n1  3.062 0.0000 24.1789 38.3213  26.1065 0.9253250 2.993341          0.8560944\n2  3.455 0.0000 22.0197 39.0877  27.3241 0.9439556 3.213508          0.8653415\n3  3.230 0.0134 22.0515 39.0884  27.3151 0.8247810 2.440971          0.7325395\n4  4.116 0.0000 23.6669 38.9699  26.7536 0.9435901 3.157702          0.8811735\n5  3.182 0.0000 23.6814 38.9708  26.7488 0.9488744 3.278296          0.8663140\n6  3.126 0.0000 23.1236 39.0054  26.9423 0.9452117 3.108474          0.8890226\n7  3.843 0.0132 23.3147 38.9885  26.8713 0.9517578 3.307644          0.9028494\n8  4.042 0.0172 22.6306 38.9094  27.0131 0.9443038 3.105908          0.8667202\n9  3.689 0.0062 22.9545 38.7777  26.8172 0.9487545 3.180393          0.9095912\n10 4.138 0.0182 23.0308 38.9967  26.9631 0.9447863 3.146480          0.8780420\n11 3.565 0.0000 22.7338 37.6204  26.0046 0.9477924 3.177766          0.8937989\n12 3.391 0.0000 22.6824 37.6627  26.0521 0.9577758 3.408022          0.9060997\n13 3.345 0.0000 22.6854 37.6176  26.0137 0.9414576 3.112066          0.8684385\n14 2.520 0.0000 22.5610 37.5960  26.0332 0.9491313 3.246802          0.8925706\n15 3.129 0.0000 18.8515 37.4542  26.9415 0.9570249 3.350694          0.9083230\n16 3.129 0.0000 18.8515 37.4542  26.9415 0.9363446 3.097474          0.8396788\n17 3.137 0.0102 24.1905 38.3192  26.1037 0.9271578 2.978541          0.8594252\n          NRI         NTI          PD        X MYNEWVAR\n1  0.18876941 -0.07458097  1.95798975 2.451799      mer\n2  0.13620072  0.17114822  1.11902329 3.127781     trap\n3  0.38351254  2.65479470 -0.01038346 2.422910 sediment\n4  0.13022700 -1.42798211 -0.64181960 3.157211     trap\n5  0.10633214 -2.49590494  0.79285403 3.433528      mer\n6  0.09438471 -0.10962187  0.81104335 2.921706     trap\n7  0.09677419 -1.21112926  0.51096388 3.282069      mer\n8  0.09438471 -0.04833770  0.26352612 2.879671      mer\n9  0.10394265  0.50404786  2.43432750 2.430342      mer\n10 0.10274791 -1.72903786 -1.62669669 3.508045 sediment\n11 0.10274791  1.12496864 -0.75543498 3.330466      mer\n12 0.09677419 -0.23029299 -0.69141166 3.688595      mer\n13 0.10991637 -2.48017258 -0.64705490 3.401944     trap\n14 0.10991637 -0.17940416 -0.67857965 3.430623 sediment\n15 0.08721625 -0.40633803  0.05055793 3.293266     trap\n16 0.14336918  1.79668405 -0.84513858 3.428512      mer\n17 0.16606930  0.12915148  0.12211753 2.969649     trap"
  },
  {
    "objectID": "Statistics.html#ii--descriptive-statistics",
    "href": "Statistics.html#ii--descriptive-statistics",
    "title": "Statistics",
    "section": " II- Descriptive statistics",
    "text": "II- Descriptive statistics\nInvestigates each variable separately. Distribution of individual variables, mean, dispersion\n\na/ Get stats info for all variables\n\n\ndescriptstats = describe(alldata)\n#see\ndescriptstats\n\n                   vars  n    mean     sd  median trimmed    mad    min     max\nRow.names*            1 17    9.00   5.05    9.00    9.00   5.93   1.00   17.00\nDescription*          2 17    2.41   1.18    2.00    2.40   1.48   1.00    4.00\nGeo*                  3 17    1.47   0.51    1.00    1.47   0.00   1.00    2.00\ngroupe*               4 17    2.59   1.18    3.00    2.60   1.48   1.00    4.00\nSiOH4                 5 17 1040.88 653.99 1295.00 1021.00 518.91 115.00 2265.00\nNO2                   6 17    2.64   0.78    2.46    2.65   0.81   1.20    3.91\nNO3                   7 17    0.17   0.07    0.14    0.17   0.06   0.08    0.26\nNH4                   8 17    0.82   0.23    0.78    0.82   0.19   0.44    1.14\nPO4                   9 17    0.43   0.13    0.43    0.43   0.12   0.22    0.66\nNT                   10 17    0.15   0.05    0.14    0.15   0.04   0.07    0.27\nPT                   11 17    8.93   0.54    8.95    8.94   0.39   7.85    9.95\nChla                 12 17    3.42   0.44    3.35    3.43   0.32   2.52    4.14\nT                    13 17    0.00   0.01    0.00    0.00   0.00   0.00    0.02\nS                    14 17   22.54   1.52   22.73   22.68   0.86  18.85   24.19\nSigma_t              15 17   38.40   0.67   38.78   38.42   0.46  37.45   39.09\nobserved             16 17   26.64   0.48   26.82   26.64   0.29  26.00   27.32\nshannon              17 17    0.94   0.03    0.94    0.94   0.01   0.82    0.96\nevenness             18 17    3.14   0.21    3.16    3.16   0.09   2.44    3.41\ndominance_relative   19 17    0.87   0.04    0.88    0.88   0.02   0.73    0.91\nNRI                  20 17    0.13   0.07    0.11    0.12   0.02   0.09    0.38\nNTI                  21 17   -0.24   1.37   -0.11   -0.28   0.91  -2.50    2.65\nPD                   22 17    0.13   1.06    0.05    0.09   1.10  -1.63    2.43\nX                    23 17    3.13   0.39    3.28    3.14   0.23   2.42    3.69\nMYNEWVAR*            24 17    1.88   0.93    2.00    1.87   1.48   1.00    3.00\n                     range  skew kurtosis     se\nRow.names*           16.00  0.00    -1.41   1.22\nDescription*          3.00  0.09    -1.59   0.29\nGeo*                  1.00  0.11    -2.10   0.12\ngroupe*               3.00 -0.09    -1.59   0.29\nSiOH4              2150.00 -0.06    -1.35 158.62\nNO2                   2.71  0.13    -1.03   0.19\nNO3                   0.17  0.18    -1.91   0.02\nNH4                   0.69  0.03    -1.30   0.05\nPO4                   0.45  0.31    -1.03   0.03\nNT                    0.20  0.63    -0.62   0.01\nPT                    2.10  0.10    -0.49   0.13\nChla                  1.62  0.12    -0.72   0.11\nT                     0.02  0.88    -1.01   0.00\nS                     5.34 -1.47     1.25   0.37\nSigma_t               1.63 -0.34    -1.81   0.16\nobserved              1.32 -0.25    -1.60   0.12\nshannon               0.13 -2.98     8.28   0.01\nevenness              0.97 -1.84     3.97   0.05\ndominance_relative    0.18 -2.12     4.77   0.01\nNRI                   0.30  2.63     6.58   0.02\nNTI                   5.15  0.16    -0.50   0.33\nPD                    4.06  0.54    -0.53   0.26\nX                     1.27 -0.65    -0.91   0.10\nMYNEWVAR*             2.00  0.21    -1.87   0.22\n\n\n\nb/ Get stats info by groups \n\n\ndescriptstats_groups = describeBy(alldata, alldata$Geo, skew=FALSE,ranges=FALSE)\n#see\ndescriptstats_groups\n\n\n Descriptive statistics by group \ngroup: EU\n                   vars n    mean     sd     se\nRow.names*            1 9    5.00   2.74   0.91\nDescription*          2 9    1.44   0.53   0.18\nGeo*                  3 9    1.00   0.00   0.00\ngroupe*               4 9    3.56   0.53   0.18\nSiOH4                 5 9 1452.78 370.60 123.53\nNO2                   6 9    3.01   0.89   0.30\nNO3                   7 9    0.20   0.06   0.02\nNH4                   8 9    0.69   0.20   0.07\nPO4                   9 9    0.50   0.13   0.04\nNT                   10 9    0.19   0.05   0.02\nPT                   11 9    8.92   0.45   0.15\nChla                 12 9    3.53   0.41   0.14\nT                    13 9    0.01   0.01   0.00\nS                    14 9   23.07   0.74   0.25\nSigma_t              15 9   38.90   0.24   0.08\nobserved             16 9   26.88   0.36   0.12\nshannon              17 9    0.93   0.04   0.01\nevenness             18 9    3.09   0.26   0.09\ndominance_relative   19 9    0.86   0.05   0.02\nNRI                  20 9    0.15   0.09   0.03\nNTI                  21 9   -0.23   1.44   0.48\nPD                   22 9    0.80   0.95   0.32\nX                    23 9    2.90   0.39   0.13\nMYNEWVAR*            24 9    1.78   0.97   0.32\n------------------------------------------------------------ \ngroup: USA\n                   vars n   mean     sd     se\nRow.names*            1 8  13.50   2.45   0.87\nDescription*          2 8   3.50   0.53   0.19\nGeo*                  3 8   2.00   0.00   0.00\ngroupe*               4 8   1.50   0.53   0.19\nSiOH4                 5 8 577.50 597.59 211.28\nNO2                   6 8   2.21   0.34   0.12\nNO3                   7 8   0.13   0.07   0.02\nNH4                   8 8   0.96   0.17   0.06\nPO4                   9 8   0.36   0.08   0.03\nNT                   10 8   0.12   0.02   0.01\nPT                   11 8   8.94   0.65   0.23\nChla                 12 8   3.29   0.46   0.16\nT                    13 8   0.00   0.01   0.00\nS                    14 8  21.95   1.98   0.70\nSigma_t              15 8  37.84   0.54   0.19\nobserved             16 8  26.38   0.47   0.17\nshannon              17 8   0.95   0.01   0.00\nevenness             18 8   3.19   0.14   0.05\ndominance_relative   19 8   0.88   0.02   0.01\nNRI                  20 8   0.11   0.03   0.01\nNTI                  21 8  -0.25   1.38   0.49\nPD                   22 8  -0.63   0.55   0.19\nX                    23 8   3.38   0.21   0.07\nMYNEWVAR*            24 8   2.00   0.93   0.33\n\n\n\nc/ Distribution plot \n\n\n#Distribution of NO2 for all data  \nggplot(data=alldata, aes(x=NO2)) +\ngeom_density(adjust=1.5, alpha=.4,show.legend=TRUE, aes(fill=\"red\"))\n\n\n\n\n\n#Distribution of NO2 separated by groups\nggplot(data=alldata, aes(x=NO2, group=Geo, fill=Geo)) +\ngeom_density(adjust=1.5, alpha=.4)"
  },
  {
    "objectID": "Statistics.html#iii--inferential-statistics-tests",
    "href": "Statistics.html#iii--inferential-statistics-tests",
    "title": "Statistics",
    "section": "III- Inferential Statistics & Tests",
    "text": "III- Inferential Statistics & Tests\n_____________________________________________________________________\nNormality test: Check the Normal or not normal distribution of your data to choose the right statistical test! - Shapiro test: H0 Null Hypothesis: follows Normal distribution! Means if p&lt;0.05 -&gt; reject the H0 (so does not follow a normal distribution)  - Q-Qplots: Compare your distribution with a theoretical normal distribution If your data follow a normal distribution, you’re expecting a linear relationship\ntheoritical vs. experimental Function indices_normality() plots the results _____________________________________________________________________\n\na/ Select indices to test & run normality check : select function\n\n\nmyselection = select(alldata, observed,NRI, evenness)\n#See\nmyselection\n\n   observed        NRI evenness\n1   26.1065 0.18876941 2.993341\n2   27.3241 0.13620072 3.213508\n3   27.3151 0.38351254 2.440971\n4   26.7536 0.13022700 3.157702\n5   26.7488 0.10633214 3.278296\n6   26.9423 0.09438471 3.108474\n7   26.8713 0.09677419 3.307644\n8   27.0131 0.09438471 3.105908\n9   26.8172 0.10394265 3.180393\n10  26.9631 0.10274791 3.146480\n11  26.0046 0.10274791 3.177766\n12  26.0521 0.09677419 3.408022\n13  26.0137 0.10991637 3.112066\n14  26.0332 0.10991637 3.246802\n15  26.9415 0.08721625 3.350694\n16  26.9415 0.14336918 3.097474\n17  26.1037 0.16606930 2.978541\n\n\n\nb/ Run Normality test: QQ-plot +Shapiro \n\n\nindices_normality(myselection, nrow =3, ncol = 2)\n\n\n\n\n4- What are your conclusions?\n5- PLease can you run a new normality test Using the parameters NO2,NO3,NH4,PO4 from the alldata object\n\nc/ The ANOVA test\nANOVA is parametric (MUST follows normal distribution) AND run at least with 3 groups or more on ONE variable  \n_____________________________________ The procedure is : \nCheck Normality \nCheck homogeneity of variance \nApply ANOVA test (global test) \nApply Post-hoc Test (pairwise group test)  _____________________________________ \nSelect number of groups \n\n\n# How many groups used? See the column \"groupe\" of alldata (4 groups A,B,C,D):\nfactor(alldata$groupe)\n\n [1] C C C C D D D D D A A A A B B B B\nLevels: A B C D\n\n\n\n# Check homogeneity of variance between groups\n# (this is to avoid bias in ANOVA result & keep the power of the test)\n# H0= equality of variances in the different populations\nbartlett.test(NH4 ~ groupe, alldata)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  NH4 by groupe\nBartlett's K-squared = 6.8824, df = 3, p-value = 0.07574\n\n\n6- Conclusion? 7-  Why I can apply ANOVA on NH4 data?\nNB: Alternative to Bartlett : Levene test (package car), less sensitive to normality deviation  \n\nApply ANOVA global test\nIMPORTANT: Global Test: Anova tell you if that some of the group means are different, but you don’t know which pairs of groups are different!\n\n\n#Global test\naov_NH4 = aov(NH4 ~ groupe, alldata)\nsummary(aov_NH4)\n\n            Df Sum Sq Mean Sq F value Pr(&gt;F)  \ngroupe       3 0.3623 0.12076   3.482 0.0473 *\nResiduals   13 0.4509 0.03469                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nApply Post-hoc test\nIMPORTANT Anova told you that there is a significant difference between some groups… but Which pairs of groups are different? -&gt; Post-hoc test answers this: Tukey multiple pairwise-comparisons\n\n\n#Pairwise-comparisons\nsignif_pairgroups = TukeyHSD(aov_NH4, method = \"bh\")\nsignif_pairgroups\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = NH4 ~ groupe, data = alldata)\n\n$groupe\n        diff        lwr         upr     p adj\nB-A  0.13175 -0.2547839  0.51828386 0.7518486\nC-A -0.15025 -0.5367839  0.23628386 0.6720556\nD-A -0.24600 -0.6126982  0.12069822 0.2486076\nC-B -0.28200 -0.6685339  0.10453386 0.1913308\nD-B -0.37775 -0.7444482 -0.01105178 0.0426827\nD-C -0.09575 -0.4624482  0.27094822 0.8680713\n\n\n\nRepresentation of tukey results\n\n\nplot(TukeyHSD(aov_NH4, conf.level=.95), las = 2)\n\n\n\n\n\nTibble table: Reformate the output statistical test for use it with graphics \n\n\nconvert_format_Tukey = broom::tidy(signif_pairgroups)\nconvert_format_Tukey\n\n# A tibble: 6 × 7\n  term   contrast null.value estimate conf.low conf.high adj.p.value\n  &lt;chr&gt;  &lt;chr&gt;         &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;\n1 groupe B-A               0   0.132    -0.255    0.518       0.752 \n2 groupe C-A               0  -0.150    -0.537    0.236       0.672 \n3 groupe D-A               0  -0.246    -0.613    0.121       0.249 \n4 groupe C-B               0  -0.282    -0.669    0.105       0.191 \n5 groupe D-B               0  -0.378    -0.744   -0.0111      0.0427\n6 groupe D-C               0  -0.0957   -0.462    0.271       0.868 \n\n\n\n split the column “contrast” into group1 et group2 (need for applying graph with p-values) \n\n\nconvert_format_Tukey = separate(convert_format_Tukey,contrast, c('group1', 'group2'),sep = \"-\")\nconvert_format_Tukey\n\n# A tibble: 6 × 8\n  term   group1 group2 null.value estimate conf.low conf.high adj.p.value\n  &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;\n1 groupe B      A               0   0.132    -0.255    0.518       0.752 \n2 groupe C      A               0  -0.150    -0.537    0.236       0.672 \n3 groupe D      A               0  -0.246    -0.613    0.121       0.249 \n4 groupe C      B               0  -0.282    -0.669    0.105       0.191 \n5 groupe D      B               0  -0.378    -0.744   -0.0111      0.0427\n6 groupe D      C               0  -0.0957   -0.462    0.271       0.868 \n\n\n\n Add a useful column\n\n\nconvert_format_Tukey$p.adj.signif = c(\"ns\",\"ns\",\"ns\",\"ns\",\"*\",\"ns\")\nconvert_format_Tukey\n\n# A tibble: 6 × 9\n  term   group1 group2 null.value estimate conf.low conf.high adj.p.value\n  &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;\n1 groupe B      A               0   0.132    -0.255    0.518       0.752 \n2 groupe C      A               0  -0.150    -0.537    0.236       0.672 \n3 groupe D      A               0  -0.246    -0.613    0.121       0.249 \n4 groupe C      B               0  -0.282    -0.669    0.105       0.191 \n5 groupe D      B               0  -0.378    -0.744   -0.0111      0.0427\n6 groupe D      C               0  -0.0957   -0.462    0.271       0.868 \n# ℹ 1 more variable: p.adj.signif &lt;chr&gt;\n\n\n\n Add another useful column\n\n\n#Build column \"custom.label\" with condition\nconvert_format_Tukey$custom.label = ifelse(convert_format_Tukey$adj.p.value &lt;= 0.05, convert_format_Tukey$adj.p.value,\"ns\")# replace convert_format_Tukey1 par convert_format_Tukey\nconvert_format_Tukey\n\n# A tibble: 6 × 10\n  term   group1 group2 null.value estimate conf.low conf.high adj.p.value\n  &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;\n1 groupe B      A               0   0.132    -0.255    0.518       0.752 \n2 groupe C      A               0  -0.150    -0.537    0.236       0.672 \n3 groupe D      A               0  -0.246    -0.613    0.121       0.249 \n4 groupe C      B               0  -0.282    -0.669    0.105       0.191 \n5 groupe D      B               0  -0.378    -0.744   -0.0111      0.0427\n6 groupe D      C               0  -0.0957   -0.462    0.271       0.868 \n# ℹ 2 more variables: p.adj.signif &lt;chr&gt;, custom.label &lt;chr&gt;\n\n\n\nbuild Boxplot with p-value \n\n\n#boxplot\nmygraph=ggplot(alldata, aes(x = groupe, y = NH4)) +\ngeom_boxplot(aes(color = groupe, fill = groupe))\nmygraph\n\n\n\n\n\n Geom_bracket() : Add p-values on graph \n\n\nmygraph + \ngeom_bracket(\naes(xmin = group1, xmax = group2, label = round(adj.p.value,2)),\ndata=convert_format_Tukey, y.position = 1.25,step.increase = 0.1,\ntip.length = 0.01, color=\"blue\")\n\n\n\n\n\n Geom_bracket() : Add significance on graph \n\n\nmygraph + \ngeom_bracket(\naes(xmin = group1, xmax = group2, label = p.adj.signif),\ndata=convert_format_Tukey, y.position = 1.25,step.increase = 0.1,\ntip.length = 0.01, color=\"blue\")\n\n\n\n\n\n Geom_bracket() :Specify One or multiple brackets manually \n\n\nmygraph + \ngeom_bracket(\nxmin = c(\"B\",\"A\"), xmax = c(\"D\",\"C\"), label = c(\"*\",\"ns\"),\ny.position = 1.5,step.increase = 0.1,\ntip.length = 0.01, color=\"blue\")\n\n\n\n\n8- Conclusion about the statistical tests for NH4?? 9- Now, do it for another Chemical parameter that follows normality…(Remember that you have check normality for other parameters see question -5)  \n\nd/ Kruskal-Wallis\n\n\n\n\n\n\n\nWarning\n\n\n\nIMPORTANT: IS non-parametric (for data not following normal distribution) & run at least on THREE or more groups for ONE variable\n\n\n________________________________________________________ Procedure is :  - Apply Kruskal GLobal test  - Apply Post-hoc Test (pairwise group test, here Dunn)  ________________________________________________________ \n\nApply Kruskal-Wallis global test\n\n\nkruskal.test(NO3 ~ groupe, data = alldata)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  NO3 by groupe\nKruskal-Wallis chi-squared = 7.4994, df = 3, p-value = 0.05757\n\n\n10- Why I’m using NO3?\n\nApply Post hoc test: Dunn test (pairwise group test)\n\n\nsignifgroup = dunnTest(NO3 ~ groupe,\n                           data = alldata,\n                           method = \"bh\")\n\nWarning: groupe was coerced to a factor.\n\n#See\nsignifgroup\n\nDunn (1964) Kruskal-Wallis multiple comparison\n\n\n  p-values adjusted with the Benjamini-Hochberg method.\n\n\n  Comparison         Z    P.unadj      P.adj\n1      A - B  1.401139 0.16117254 0.32234509\n2      A - C -1.120911 0.26232570 0.39348855\n3      B - C -2.522050 0.01166731 0.07000387\n4      A - D -0.738465 0.46023191 0.55227829\n5      B - D -2.215395 0.02673296 0.08019887\n6      C - D  0.443079 0.65770858 0.65770858\n\n\n11- Conclusion?? 12- Do you think that it was necessary to make the Post-hoc test? why? 13- Add a new categorical variable (=not numerical, exple the groupe column) in the table that allows forming 3 groups  14- Use NRI numerical variable and run Kruskal test with your new categorical variable, post-hoc test & boxblot representation \n\ne/ T-test\n\n\n\n\n\n\n\nWarning\n\n\n\nIMPORTANT: Test is parametric= follow normal distribution,homogeneity of variance & run on 2 groups (ONE variable)\n\n\n\nSelect the groups\n\n\n#Geo column\nfactor(alldata$Geo)\n\n [1] EU  EU  EU  EU  EU  EU  EU  EU  EU  USA USA USA USA USA USA USA USA\nLevels: EU USA\n\n\n\nCheck homogeneity of variance\n\n\nbartlett.test(PO4 ~ Geo, alldata)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  PO4 by Geo\nBartlett's K-squared = 1.8936, df = 1, p-value = 0.1688\n\n\n15- Can I run t-test according to homogeneity of variance result?Why?\n\n#run t-test\nobserved_ttest = t.test(PO4 ~ Geo, data = alldata)\n#see result\nobserved_ttest\n\n\n    Welch Two Sample t-test\n\ndata:  PO4 by Geo\nt = 2.8078, df = 13.108, p-value = 0.01471\nalternative hypothesis: true difference in means between group EU and group USA is not equal to 0\n95 percent confidence interval:\n 0.03408592 0.26074742\nsample estimates:\n mean in group EU mean in group USA \n        0.5036667         0.3562500 \n\n\n16- Conclusion?\n\nf/ Wilcoxon rank-sum test \n\n\n\n\n\n\n\nWarning\n\n\n\nIMPORTANT: Is non-parametric (not follow normal distrib) & runs on 2 Groups and ONE variable\n\n\n\npairwise_test = compare_means(NO3 ~ Geo,\n                                       alldata,\n                                       method = \"wilcox.test\")\n#See\npairwise_test\n\n# A tibble: 1 × 8\n  .y.   group1 group2      p p.adj p.format p.signif method  \n  &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;   \n1 NO3   EU     USA    0.0237 0.024 0.024    *        Wilcoxon\n\n\n17- Why the choice of NO3? Conclusion?\n\nBoxplot representation with p-value using stat_pvalue_manual \n\n\n#Boxplot as previously seen\ngraph_shan = ggplot(alldata, aes(x = Geo, y = NO3)) + \n  geom_boxplot(alpha=0.6,\n               fill = c(\"#00AFBB\", \"#E7B800\"),\n               color = c(\"#00AFBB\", \"#E7B800\")) +\n  geom_jitter(aes(colour = groupe),\n              position = position_jitter(0.02) ,\n              cex=2.2) +\n  stat_summary(fun = mean, geom = \"point\",\n               shape = 17, size = 3,\n               color = \"white\")\n#see\ngraph_shan\n\n\n\n\n\nAdd p-value on graph\n\n\ngraph_shan + stat_pvalue_manual(\n  pairwise_test,\n  y.position = 0.3,\n  label = \"p.adj = {p.adj}\",\n  color = \"blue\",\n  linetype = 1,\n  tip.length = 0.02\n)"
  },
  {
    "objectID": "Statistics.html#iv--bivariate-analysis",
    "href": "Statistics.html#iv--bivariate-analysis",
    "title": "Statistics",
    "section": "IV- Bivariate Analysis ",
    "text": "IV- Bivariate Analysis \n________________________________________________________________ Study the relationship between two variables (quantitatives or qualitatives) ________________________________________________________________\n\nA- Correlation analysis\nImportant : Correlation coefficient r  is independent of change of origin and scale (So no data transformation!!) Correlation analysis describes the nature (strength (0 to 1) and direction Positive/Negative) of the relationship  between two quantitative variables (r),whatever the range and the measurement units of them. ___________________________ Methods & conditions :  - Pearson : Parametric  - Spearman: Non-Parametric  - Kendall : Non-parametric  ___________________________ The procedure is :  - Select your variables of interest - Test the Normality of data - Choose the right method according Normality result - Apply Correlation method - Apply statistical test - Build the final plot ___________________________\n\na1/ Select variables that you want\n\n\n#Select variables for bivariate correlation\nmyvariables = select(alldata, SiOH4:PO4, observed,PD)\n#see\nmyvariables\n\n   SiOH4   NO2   NO3   NH4   PO4 observed          PD\n1    945 2.669 0.136 0.785 0.267  26.1065  1.95798975\n2   1295 2.206 0.249 0.768 0.629  27.3241  1.11902329\n3   1300 3.004 0.251 0.727 0.653  27.3151 -0.01038346\n4   1600 3.016 0.257 0.695 0.491  26.7536 -0.64181960\n5   1355 1.198 0.165 1.099 0.432  26.7488  0.79285403\n6   1590 3.868 0.253 0.567 0.533  26.9423  0.81104335\n7   2265 3.639 0.255 0.658 0.665  26.8713  0.51096388\n8   1180 3.910 0.107 0.472 0.490  27.0131  0.26352612\n9   1545 3.607 0.139 0.444 0.373  26.8172  2.43432750\n10  1690 2.324 0.083 0.856 0.467  26.9631 -1.62669669\n11   115 1.813 0.256 0.889 0.324  26.0046 -0.75543498\n12   395 2.592 0.105 1.125 0.328  26.0521 -0.69141166\n13   395 2.381 0.231 0.706 0.450  26.0137 -0.64705490\n14   200 1.656 0.098 0.794 0.367  26.0332 -0.67857965\n15   235 2.457 0.099 1.087 0.349  26.9415  0.05055793\n16   235 2.457 0.099 1.087 0.349  26.9415 -0.84513858\n17  1355 2.028 0.103 1.135 0.216  26.1037  0.12211753\n\n\n\na2/ Normality\n\n\nindices_normality(myvariables, nrow =3, ncol = 3)\n\n\n\n\n18- &lt;span style=“color: red;”Conclusions, which method to apply?\n\na3/ Apply the Pearson method\n\n\n#Apply method pearson\nmatrixCor = cor(myvariables, method = \"pearson\")\n#see\nmatrixCor\n\n              SiOH4        NO2        NO3        NH4         PO4   observed\nSiOH4     1.0000000  0.4856257  0.3140398 -0.4513788  0.56085793  0.5066938\nNO2       0.4856257  1.0000000  0.2124683 -0.7269246  0.41715983  0.4170527\nNO3       0.3140398  0.2124683  1.0000000 -0.4036942  0.63751606  0.1928259\nNH4      -0.4513788 -0.7269246 -0.4036942  1.0000000 -0.51338488 -0.2944559\nPO4       0.5608579  0.4171598  0.6375161 -0.5133849  1.00000000  0.7054092\nobserved  0.5066938  0.4170527  0.1928259 -0.2944559  0.70540919  1.0000000\nPD        0.3665477  0.3343467  0.1300303 -0.3958036  0.04168105  0.1832832\n                  PD\nSiOH4     0.36654770\nNO2       0.33434675\nNO3       0.13003033\nNH4      -0.39580362\nPO4       0.04168105\nobserved  0.18328322\nPD        1.00000000\n\n\n\nSave the table with correlation values\n\n\nwrite.table(matrixCor,file=\"./correlation_matrix.txt\",sep = \"\\t\")\n\n\na4/ Plot results: corrplot function\n\n\ncorrplot(\n  matrixCor,\n  method=\"circle\",\n  type=\"lower\",\n  order='hclust',\n  tl.col = \"black\",\n  tl.srt = 45,\n  tl.cex=0.9,\n  diag = FALSE\n)\n\n\n\n\n\na5/ Is the correlation is due to chance? Significance test!\n______________________________________________________ The idea:\nTest the correlation at the population scale (= increase data , it’s call Rho) and compare to r (your samples)  H0 is : There is no significant linear correlation between X and Y variables in the population  For instance a t-test allows to use sample data to generalize an assumption to an entire population ______________________________________________________\n\n\n#Test stats\nptest =cor.mtest(matrixCor, conf.level = .95)\n\n\n#ptest is a list... see \nclass(ptest)\n\n[1] \"list\"\n\n\n\n\n#See the list\nptest\n\n$p\n              SiOH4        NO2        NO3        NH4        PO4   observed\nSiOH4    0.00000000 0.03104693 0.23694105 0.01713865 0.04594221 0.06146485\nNO2      0.03104693 0.00000000 0.30094151 0.00110837 0.09506126 0.10206651\nNO3      0.23694105 0.30094151 0.00000000 0.09663095 0.03311411 0.39456306\nNH4      0.01713865 0.00110837 0.09663095 0.00000000 0.03715039 0.10437538\nPO4      0.04594221 0.09506126 0.03311411 0.03715039 0.00000000 0.01782655\nobserved 0.06146485 0.10206651 0.39456306 0.10437538 0.01782655 0.00000000\nPD       0.23167149 0.18000316 0.73582000 0.12998482 0.77570253 0.65179758\n                PD\nSiOH4    0.2316715\nNO2      0.1800032\nNO3      0.7358200\nNH4      0.1299848\nPO4      0.7757025\nobserved 0.6517976\nPD       0.0000000\n\n$lowCI\n               SiOH4        NO2        NO3        NH4         PO4    observed\nSiOH4     1.00000000  0.1158642 -0.3889387 -0.9763259  0.02371354 -0.04704726\nNO2       0.11586418  1.0000000 -0.4500231 -0.9926251 -0.15583006 -0.17380558\nNO3      -0.38893869 -0.4500231  1.0000000 -0.9466621  0.10098312 -0.51886347\nNH4      -0.97632595 -0.9926251 -0.9466621  1.0000000 -0.96636922 -0.94453657\nPO4       0.02371354 -0.1558301  0.1009831 -0.9663692  1.00000000  0.23878062\nobserved -0.04704726 -0.1738056 -0.5188635 -0.9445366  0.23878062  1.00000000\nPD       -0.38318235 -0.3185439 -0.6756654 -0.9378870 -0.68891124 -0.64526193\n                 PD\nSiOH4    -0.3831823\nNO2      -0.3185439\nNO3      -0.6756654\nNH4      -0.9378870\nPO4      -0.6889112\nobserved -0.6452619\nPD        1.0000000\n\n$uppCI\n              SiOH4        NO2       NO3         NH4         PO4  observed\nSiOH4     1.0000000  0.9690429 0.9136889 -0.24712040  0.96285638 0.9573268\nNO2       0.9690429  1.0000000 0.9005713 -0.68559598  0.94710076 0.9451638\nNO3       0.9136889  0.9005713 1.0000000  0.15996568  0.96811152 0.8821061\nNH4      -0.2471204 -0.6855960 0.1599657  1.00000000 -0.07415082 0.1794714\nPO4       0.9628564  0.9471008 0.9681115 -0.07415082  1.00000000 0.9759077\nobserved  0.9573268  0.9451638 0.8821061  0.17947138  0.97590766 1.0000000\nPD        0.9147994  0.9260528 0.8140329  0.23527330  0.80550109 0.8314534\n                PD\nSiOH4    0.9147994\nNO2      0.9260528\nNO3      0.8140329\nNH4      0.2352733\nPO4      0.8055011\nobserved 0.8314534\nPD       1.0000000\n\n\n\n\n#to see only the p-values you must call ptest$p\nptest$p \n\n              SiOH4        NO2        NO3        NH4        PO4   observed\nSiOH4    0.00000000 0.03104693 0.23694105 0.01713865 0.04594221 0.06146485\nNO2      0.03104693 0.00000000 0.30094151 0.00110837 0.09506126 0.10206651\nNO3      0.23694105 0.30094151 0.00000000 0.09663095 0.03311411 0.39456306\nNH4      0.01713865 0.00110837 0.09663095 0.00000000 0.03715039 0.10437538\nPO4      0.04594221 0.09506126 0.03311411 0.03715039 0.00000000 0.01782655\nobserved 0.06146485 0.10206651 0.39456306 0.10437538 0.01782655 0.00000000\nPD       0.23167149 0.18000316 0.73582000 0.12998482 0.77570253 0.65179758\n                PD\nSiOH4    0.2316715\nNO2      0.1800032\nNO3      0.7358200\nNH4      0.1299848\nPO4      0.7757025\nobserved 0.6517976\nPD       0.0000000\n\n\n19- Save the result in a file 20- Can you display only the value of PD column of ptest$p (help: first check the class of ptest$p)?  \n\na6/ Plot only correlations with significant p-values\n\n\ncorrplot(\n  matrixCor,\n  p.mat = ptest$p,\n  sig.level = .05,\n  method = \"circle\",\n  type = \"lower\",\n  order = 'hclust',\n  tl.col = \"black\",\n  tl.srt = 45,\n  tl.cex = 0.7,\n  diag = FALSE\n)\n\n\n\n\n\n\nB- Linear regression \n______________________________________________________________________ Determination of coefficient R2 provides percentage variation in Y which is explained by all the X together. Its value is (usually) between 0 and 1 and it indicates strength of Linear Regression model. -  High R2 value, data points are less scattered so it is a good model - Low R2 value is more scattered the data points ______________________________________________________________________\n\nb1/ Regression Shannon ~ Observed \n\n\nggplot(alldata, aes(x = observed, y = shannon)) +\n  geom_point() +\n  stat_smooth(method = \"lm\", col = \"red\") +\n  stat_poly_eq(aes(label = paste(after_stat(rr.label),\n                                          after_stat(p.value.label),\n                                          sep = \"*\\\", \\\"*\")))\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n21- What is the question we try to answer? 22- Conclusion?\n\nb2/ Linear Regression NH4 ~ NO2 \n\n\nggplot(alldata, aes(x = NO2, y = NH4)) +\n  geom_point() +\n  stat_smooth(method = \"lm\", col = \"red\") +\n  stat_poly_eq(aes(label = paste(after_stat(rr.label),\n                                          after_stat(p.value.label),\n                                          sep = \"*\\\", \\\"*\")))\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n23- What are √R2 of this exemple? See matrixCor… Do you see the relation beetween R2 and r?\n if you not see, try to run in the console: cor(alldata$NH4, alldata$NO2) \n\n BUT\n\n Remember that you have two population groups (EU vs USA) in the data\n\nggplot(alldata, aes(x = NO2, y = NH4, col=Geo)) +\n  geom_point() +\n  stat_smooth(method = \"lm\", col = \"red\") +\n  stat_poly_eq(aes(label = paste(after_stat(rr.label),\n                                          after_stat(p.value.label),\n                                          sep = \"*\\\", \\\"*\")))\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n AND MORE… \nfacet_grid option to separate the two graph\n\n\nggplot(alldata, aes(x = NO2, y = NH4, col=Geo)) +\n  geom_point() +\n  stat_smooth(method = \"lm\", col = \"red\") +\n  stat_poly_eq(aes(label = paste(after_stat(rr.label),\n                                          after_stat(p.value.label),\n                                          sep = \"*\\\", \\\"*\")))+\n  facet_grid(rows=vars(Geo))\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n BONUS \nMake linear regression + add correlation r coeficent for numerous variable in ONE step!! Allow you to rapidely see wich variables are correlated among a huge list.\n\n\npairs(alldata[, c(\"NH4\",\"NO3\", \"NO2\",\"PO4\", \"observed\")],upper.panel = regression_line, lower.panel=panel.cor) \n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter"
  }
]